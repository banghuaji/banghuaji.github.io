{"meta":{"title":"JIMI的博客","subtitle":"主孰有道？将孰有能？天地孰得？法令孰行？兵众孰强？士卒孰练？赏罚孰明？吾以此知胜负矣。","description":"努力超越那个谁","author":"JIMI","url":"https://banghuaji.github.io"},"pages":[{"title":"","date":"2017-10-01T12:38:16.285Z","updated":"2017-10-01T12:37:48.000Z","comments":true,"path":"404.html","permalink":"https://banghuaji.github.io/404.html","excerpt":"","text":""},{"title":"customizeds","date":"2017-10-31T14:56:07.000Z","updated":"2017-10-31T15:01:42.178Z","comments":true,"path":"customizeds/index.html","permalink":"https://banghuaji.github.io/customizeds/index.html","excerpt":"","text":"关于我一只学习的小菜鸟，欢迎分享知识。 From JIMI QQ：516316976Email: 516316976@qq.com"},{"title":"categories","date":"2017-10-01T13:21:45.000Z","updated":"2017-10-31T14:12:22.177Z","comments":false,"path":"categories/index.html","permalink":"https://banghuaji.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-10-01T13:21:45.000Z","updated":"2017-10-01T13:24:28.000Z","comments":true,"path":"tags/index.html","permalink":"https://banghuaji.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"有货在Kubernetes容器环境的CD实践","slug":"docker/有货在Kubernetes容器环境的CD实践","date":"2018-08-21T09:10:06.420Z","updated":"2018-08-21T09:20:35.458Z","comments":true,"path":"2018/08/21/docker/有货在Kubernetes容器环境的CD实践/","link":"","permalink":"https://banghuaji.github.io/2018/08/21/docker/有货在Kubernetes容器环境的CD实践/","excerpt":"","text":"分享内容： spinnaker介绍与安装踩过的坑。 spinnaker在kubernetes的持续部署。 线上容器服务的选择与多区容灾。 spinnaker介绍Spinnaker 是 Netflix 的开源项目，是一个持续交付平台，它定位于将产品快速且持续的部署到多种云平台上。Spinnaker 有两个核心的功能集群管理和部署管理。Spinnaker 通过将发布和各个云平台解耦，来将部署流程流水线化，从而降低平台迁移或多云品台部署应用的复杂度，它本身内部支持 Google、AWS EC2、Microsoft Azure、Kubernetes和 OpenStack 等云平台，并且它可以无缝集成其他持续集成（CI）流程，如 git、Jenkins、Travis CI、Docker registry、cron 调度器等。 应用管理spinnaker主要用于展示与管理你的云端资源.先要了解一些关键的概念：Applications, clusters, and server groups,通过Load balancers and firewalls 将服务展示给用户。官方给的结构如下： Application定义了集群中一组的cluster的集合，也包括了firewalls 与 load balancers，存储了服务所有的部署相关的的信息。 Server Group定义了一些基础的源比如(VM image, Docker image),以及一些基础的配置信息，一旦部署后，在容器中对应Kubernetes pods的集合。 ClusterServer Groups的有关联的集合。（Cluster中可以按照dev，prod的去创建不同的服务组），也可以理解为对于一个应用存在多个分支的情况。 Load Balancer他在实例之间做负载均衡流量。您还可以为负载均衡器启用健康检查，灵活地定义健康标准并指定健康检查端点，有点类似于kubernetes中ingress。 Firewall防火墙定义了网络流量访问，定义了一些访问的规则，如安全组等等。 页面预览页面展示如下，还是比较精简的，可以在它的操作页面上看到项目以及应用的详细信息，还可以进行集群的伸缩，回滚，修改以及删除的操作。 部署管理上图中，infrastructure左侧为PIPELINE的设计：主要讲两块内容：pipeline的创建以及基础功能，与部署的策略。 Pipeline 较强的 Pipeline 的能力：它的 Pipeline 可以复杂到无以复加，它还有很强的表达式功能(后续的操作中前面的参数均通过表达式获取)。 触发的方式：定时任务，人工触发，jenkinsjob，docker images，或者其他的pipeline的步骤。 通知方式：email, SMS or HipChat. 将所有的操作都融合到pipeline中，比如回滚、金丝雀分析、关联CI等等。 部署策略由于我们用的是Kubernetes Provider V2 (Manifest Based) 方式：可修改yaml中：spec.strategy.type。 Recreate，先将所有旧的Pod停止，然后再启动新的pod对应其中的第一种方式。 RollingUpdate，即滚动升级，对应下图中第二种方式 canary下面会单独的介绍其中的使用。 spinnaker安装踩过的坑很多人都是感觉这个很难安装，其实主要的原因还是墙的问题，只要把这个解决了就会方便很多，官方的文档写的很详细，而且spinnaker的社区也非常的活跃，有问题均可以在上面进行提问。 安装提供的方式： Halyard安装方式(官方推荐安装方式) 我采用Halyard安装方式，因为后期我们会集成很多其他的插件，类似于gitlab，ldap，kayenta，甚至多个jenkins，kubernetes服务等等，可配置性较强。 Helm搭建Spinnaker平台 Development版本安装 helm方式若是需要自定义一些个性化的内容会比较复杂，完全依赖于原始镜像，而Development需要对spinnaker非常的熟悉，以及每个版本之间的对应关系均要了解。 Halyard方式安装注意点：Halyard代理的配置12vim /opt/halyard/bin/halyardDEFAULT_JVM_OPTS=&apos;-Dhttp.proxyHost=192.168.102.10 -Dhttps.proxyPort=3128&apos; 部署机器选择由于spinnaker涉及的应用较多，下面会单独的介绍，需要消耗比较大的内存，官方推荐的配置如下：12318 GB of RAMA 4 core CPUUbuntu 14.04, 16.04 or 18.04 spinnaker安装步骤 Halyard下载以及安装 选择云提供者：我选择的是Kubernetes Provider V2 (Manifest Based)，需要在部署spinnaker的机器上完成K8S集群的认证，以及权限管理。 部署的时候选择安装环境：我选择的是Debian包的方式。 选择存储：官方推荐使用minio，我选择的是minio的方式。 选择安装的版本：我当时最新的是V1.8.0 接下来进行部署工作，初次部署时间较长，会连接代理下载对应的包。 全部下载与完成后，查看对应的日志，即可使用localhost:9000访问即可。 完成以上的步骤则可以在kubernetes上面部署对应的应用了。 涉及的组件下图是spinnaker的各个组件之间的关系。 Deck：面向用户 UI 界面组件，提供直观简介的操作界面，可视化操作发布部署流程。 API： 面向调用 API 组件，我们可以不使用提供的 UI，直接调用 API 操作，由它后台帮我们执行发布等任务。 Gate：是 API 的网关组件，可以理解为代理，所有请求由其代理转发。 Rosco：是构建 beta 镜像的组件，需要配置 Packer 组件使用。 Orca：是核心流程引擎组件，用来管理流程。 Igor：是用来集成其他 CI 系统组件，如 Jenkins 等一个组件。 Echo：是通知系统组件，发送邮件等信息。 Front50：是存储管理组件，需要配置 Redis、Cassandra 等组件使用。 Cloud driver 是它用来适配不同的云平台的组件，比如 Kubernetes，Google、AWS EC2、Microsoft Azure 等。 Fiat 是鉴权的组件，配置权限管理，支持 OAuth、SAML、LDAP、GitHub teams、Azure groups、 Google Groups 等。 组件 端口 依赖组件 端口 Clouddriver 7002 Minio Fiat 7003 Jenkins Front50 8080 Ldap Orca 8083 github Gate 8084 Rosco 8087 Igor 8088 Echo 8089 Deck 9000 kayenta 8090 spinnaker在kubernetes的持续部署PIPELINE部署示例如下pipeline设计就是开发将版本合到某一个分支后，通过jenkins镜像构建，发布测试环境，进而自动化以及人工验证，在由人工判断是否需要发布到线上以及回滚，若是选择发布到线上则发布到prod环境，从而进行prod自动化的CI。若是选择回滚则回滚到上个版本，从而进行dev自动化的CI。 Stage-configuration设置触发的方式，定义全局变量，执行报告的通知方式，是pipeline的起点 Automated Triggers其中支持多种触发的方式：定时任务corn，git，jenkins，docker Registry，travis,pipeline,webhook等触发方式，从而能够满足我们自动回调的功能。 Parameters此处定义的全局变量会在整个PIPELINE中使用${ parameters[‘branch’]}得到,这样大大的简化了我们设计pipeline的通用性。 Notifications这里通知支持：SMS，EMAIL，HIPCHAT等等的方式。我们使用了邮件通知的功能：需要在echo的配置文件中加入发件邮箱的基本信息。 Stage-jenkins调用jenkins来执行相关的任务，其中jenkins的服务信息存在放hal的配置文件中（如下展示），spinnaker可自动以同步jenkins的job以及参数等等的信息，运行后能够看到对应的JOB ID以及状态： 运行完成后展示如下，我们可以查看相关的build的信息，以及此stage执行的相关信息，点击build可以跳到对应的jenkins的job查看相关的任务信息。 Stage-deploy由于我们配置spinnaker的时候采用的是Kubernetes Provider V2方式，我们的发布均采用yaml的方式来实现，可以将文件存放在github中或者直接在页面上进行配置，同时yaml中文件支持了很多的参数化，这样大大的方便了我们日常的使用。 halyard关联KUBERNETES的配置信息由于我们采用的云服务是KUBERNETES，配置的时候需要将部署spinnaker的机器对KUBERNETES集群做认证。 spinnaker发布信息展示：此处Manifest Source支持参数化形式，类似于我们写入的yaml部署文件，但是这里支持参数化的方式。具体的配置项如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: &apos;$&#123; parameters.deployName &#125;-deployment&apos; namespace: dev spec: replicas: 2 template: metadata: labels: name: &apos;$&#123; parameters.deployName &#125;-deployment&apos; spec: containers: - image: &gt;- 192.168.105.2:5000/$&#123; parameters.imageSource &#125;/$&#123; parameters.deployName &#125;:$&#123; parameters.imageversion &#125; name: &apos;$&#123; parameters.deployName &#125;-deployment&apos; ports: - containerPort: 8080 imagePullSecrets: - name: registrypullsecret- apiVersion: v1 kind: Service metadata: name: &apos;$&#123; parameters.deployName &#125;-service&apos; namespace: dev spec: ports: - port: 8080 targetPort: 8080 selector: name: &apos;$&#123; parameters.deployName &#125;-deployment&apos;- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: &apos;$&#123; parameters.deployName &#125;-ingress&apos; namespace: dev spec: rules: - host: &apos;$&#123; parameters.deployName &#125;-dev.ingress.dev.yohocorp.com&apos; http: paths: - backend: serviceName: &apos;$&#123; parameters.deployName &#125;-service&apos; servicePort: 8080 path: / 运行结果的示例： Stage-Webhookwebhook我们可以做一些简单的环境验证以及去调用其他的服务的功能，它自身也提供了一些结果的验证功能，支持多种请求的方式。 运行结果的示例： Stage-Manual Judgmentspinnaker配置信息用于人工的逻辑判断，增加pipeline的控制性(比如发布到线上需要测试人员认证以及领导审批)，内容支持多种语法表达的方式。 运行结果的示例 Stage-Check Preconditions上边 Manual Judgment Stage 配置了两个 Judgment Inputs 判断项，接下来我们建两个 Check Preconditions Stage 来分别对这两种判断项做条件检测，条件检测成功，则执行对应的后续 Stage 流程。比如上面的操作，若是选择发布到prod，则执行发布到线上的分支，若是选择执行回滚的操作则进行回滚相关的分支。 spinnaker配置信息 运行结果的示例如上图中我选择了rollback则prod分支判断为失败，会阻塞后面的stage运行。 Stage-Undo Rollout (Manifest)若是我们发布发现出现问题，也可以设计回滚的stage，spinnaker的回滚极其的方便，在我们的日常部署中，每个版本都会存在对应的部署记录，如下所示： spinnakerpipeline配置信息回滚的pipeline描述中我们需要选择对应的deployment的回滚信息，以及回滚的版本数量。 运行结果的示例 Stage-Canary Analysis金丝雀部署方式：在我们发布新版本时引入部分流量到canary的服务中，kayenta会读取spinnaker中配置的prometheus中收集的指标，比如内存，CPU，接口超时时间，失败率等等通过kayenta中NetflixACAJudge来进行分析与判断，将分析的结果存于S3中，最终会给出这段时间的最终结果。 Canary分析主要经过如下四个步骤： 验证数据 清理数据 比对指标 分数计算 设计的模型如下： 运行结果的设计与展示 我们需要对应用开启canary的配置。 创建出baseline与canary的deployment由同一个service指向这两个deployment。 我们这里采用读取prometheus的指标，需要在hal中增加prometheus配置。Metric可以直接匹配prometheus的指标。需要配置收集指标以及指标的权重 在pipeline中指定收集分析的频率以及需要指定的源，同时可以配置scoring从而覆盖模板中的配置。 每次分析的执行记录： 结果展示如下，由于我们设置的目标是75，所以pipeline的结果判定为失败。 线上容器服务的选择与多区容灾。我们是腾讯云的客户，采用腾讯云容器服务主要看重以下几个方面: Kubernetes在自搭建的集群中，要实现Overlay网络，在腾讯云的环境里，它本身就是软件定义网络VPC，所以它在网络上的实现可以做到在容器环境里和原生的VM网络一样的快，没有任何的性能牺牲。 应用型负载均衡器和Kubernetes里的ingress相关联，对于需要外部访问的服务能够快速的创建。 腾讯云的云储存可以被Kubernetes管理，便于持久化的操作。 腾讯云的部署以及告警也对外提供了服务与接口，可以更好的查看与监控相关的node与pod的情况。 腾讯云日志服务很好的与容器进行融合，能够方便的收集与检索日志。 下图是我们在线上以及灰度环境的发布示意图：为了容灾我们使用了北京二区与北京三区两个集群，若是需要灰度验证时，则将线上北京三区的权重修改为0，这样通过灰度负载均衡器即可到达新版本应用。日常使用中二区与三区均同时提供挂服务。","categories":[],"tags":[{"name":"spinnaker","slug":"spinnaker","permalink":"https://banghuaji.github.io/tags/spinnaker/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://banghuaji.github.io/tags/kubernetes/"}]},{"title":"kubernetes-module---kube-proxy","slug":"container/kubernetes-module---kube-proxy","date":"2018-07-30T08:33:14.778Z","updated":"2018-07-30T08:34:09.556Z","comments":true,"path":"2018/07/30/container/kubernetes-module---kube-proxy/","link":"","permalink":"https://banghuaji.github.io/2018/07/30/container/kubernetes-module---kube-proxy/","excerpt":"","text":"kubernetes版本大于或者等于1.2时，外部网络（即非K8S集群内的网络）访问cluster IP的办法是：修改master的/etc/kubernetes/proxy，把KUBE_PROXY_ARGS=”“改为KUBE_PROXY_ARGS=”–proxy-mode=userspace” kuer-proxy目前有userspace和iptables两种实现方式。userspace（如下图）是在用户空间，通过kuber-proxy实现LB的代理服务。在K8S1.2版本之前，是kube-proxy默认方式，所有的转发都是通过kube-proxy实现的。这个是kube-proxy的最初的版本，较为稳定，但是效率也自然不太高。 另外一种方式是iptables方式（如下图）。是纯采用iptables来实现LB。在K8S1.2版本之后，kube-proxy默认方式。所有转发都是通过Iptables内核模块实现，而kube-proxy只负责生成相应的Iptables规则。 iptable解析iptables的方式则是利用了linux的iptables的nat转发进行实现123456789101112131415161718192021222324252627282930313233[root@Hadoop-NN-01 ~]# iptables -S -t nat |grep tomcat-server-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp --dport 31002 -j KUBE-MARK-MASQ-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp --dport 31002 -j KUBE-SVC-WFVL53WIZBEOA3P2-A KUBE-SEP-5UN7SRPB24XQJI43 -s 172.17.0.6/32 -m comment --comment &quot;default/tomcat-server:&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-5UN7SRPB24XQJI43 -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp -j DNAT --to-destination 172.17.0.6:8080-A KUBE-SEP-7NEIUJRBV2MEHT4H -s 172.17.0.5/32 -m comment --comment &quot;default/tomcat-server:&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-7NEIUJRBV2MEHT4H -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp -j DNAT --to-destination 172.17.0.5:8080-A KUBE-SEP-VMZDO22SZA7LLNHA -s 172.17.0.4/32 -m comment --comment &quot;default/tomcat-server:&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-VMZDO22SZA7LLNHA -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp -j DNAT --to-destination 172.17.0.4:8080-A KUBE-SEP-XJDMG6H2QTPJ5WFT -s 172.17.0.3/32 -m comment --comment &quot;default/tomcat-server:&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-XJDMG6H2QTPJ5WFT -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp -j DNAT --to-destination 172.17.0.3:8080-A KUBE-SERVICES -d 10.254.51.49/32 -p tcp -m comment --comment &quot;default/tomcat-server: cluster IP&quot; -m tcp --dport 8080 -j KUBE-SVC-WFVL53WIZBEOA3P2-A KUBE-SVC-WFVL53WIZBEOA3P2 -m comment --comment &quot;default/tomcat-server:&quot; -m statistic --mode random --probability 0.25000000000 -j KUBE-SEP-XJDMG6H2QTPJ5WFT-A KUBE-SVC-WFVL53WIZBEOA3P2 -m comment --comment &quot;default/tomcat-server:&quot; -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-VMZDO22SZA7LLNHA-A KUBE-SVC-WFVL53WIZBEOA3P2 -m comment --comment &quot;default/tomcat-server:&quot; -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-7NEIUJRBV2MEHT4H-A KUBE-SVC-WFVL53WIZBEOA3P2 -m comment --comment &quot;default/tomcat-server:&quot; -j KUBE-SEP-5UN7SRPB24XQJI43首先如果是通过node的31002端口访问，则会进入到以下链-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp --dport 31002 -j KUBE-MARK-MASQ-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp --dport 31002 -j KUBE-SVC-WFVL53WIZBEOA3P2然后进一步跳转到KUBE-SVC-WFVL53WIZBEOA3P2的链这里利用了iptables的--probability的特性，按照POD的个数来计算其中的可能性。-A KUBE-SVC-WFVL53WIZBEOA3P2 -m comment --comment &quot;default/tomcat-server:&quot; -m statistic --mode random --probability 0.25000000000 -j KUBE-SEP-XJDMG6H2QTPJ5WFT-A KUBE-SVC-WFVL53WIZBEOA3P2 -m comment --comment &quot;default/tomcat-server:&quot; -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-VMZDO22SZA7LLNHA-A KUBE-SVC-WFVL53WIZBEOA3P2 -m comment --comment &quot;default/tomcat-server:&quot; -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-7NEIUJRBV2MEHT4H-A KUBE-SVC-WFVL53WIZBEOA3P2 -m comment --comment &quot;default/tomcat-server:&quot; -j KUBE-SEP-5UN7SRPB24XQJI43现在最后一条：同理KUBE-SEP-5UN7SRPB24XQJI43的作用是通过DNAT发送到172.17.0.6的8080端口。-A KUBE-SEP-5UN7SRPB24XQJI43 -s 172.17.0.6/32 -m comment --comment &quot;default/tomcat-server:&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-5UN7SRPB24XQJI43 -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp -j DNAT --to-destination 172.17.0.6:8080 分析完nodePort的工作方式，接下里说一下clusterIP的访问方式。1-A KUBE-SERVICES -d 10.254.51.49/32 -p tcp -m comment --comment &quot;default/tomcat-server: cluster IP&quot; -m tcp --dport 8080 -j KUBE-SVC-WFVL53WIZBEOA3P2 userspace123456789 KUBE_PROXY_ARGS=&quot; --proxy-mode=userspace&quot;摘录表格：[root@Hadoop-NN-01 ~]# iptables -S -t nat |grep tomcat-server-A KUBE-NODEPORT-CONTAINER -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp --dport 31002 -j REDIRECT --to-ports 57310-A KUBE-NODEPORT-HOST -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp --dport 31002 -j DNAT --to-destination 172.16.6.63:57310-A KUBE-PORTALS-CONTAINER -d 10.254.51.49/32 -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp --dport 8080 -j REDIRECT --to-ports 57310-A KUBE-PORTALS-HOST -d 10.254.51.49/32 -p tcp -m comment --comment &quot;default/tomcat-server:&quot; -m tcp --dport 8080 -j DNAT --to-destination 172.16.6.63:57310 从其中可以看出：当请求到31002端口时，会被转发到pod 172.16.6.63:57310端口，而当我们请求本地的port：8080时也会请求到172.16.6.63:57310端口 123可以看出端口57310 是被kube-proxy监听的，[root@Hadoop-NN-01 ~]# netstat -apn |grep 57310tcp6 0 0 :::57310 :::* LISTEN 16671/kube-proxy","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://banghuaji.github.io/tags/kubernetes/"}]},{"title":"linux文件权限","slug":"linux/文件与文件夹创建的默认权限","date":"2018-07-22T13:27:26.832Z","updated":"2018-07-22T13:27:04.898Z","comments":true,"path":"2018/07/22/linux/文件与文件夹创建的默认权限/","link":"","permalink":"https://banghuaji.github.io/2018/07/22/linux/文件与文件夹创建的默认权限/","excerpt":"","text":"问题发现：问题：容器中部署Java应用，将日志文件映射到宿主机，创建的目录权限为：以及文件的权限为：如下 1234567root@192-168-104-194:/opt/test/activity# lltotal 72drwxr-xr-x 3 root root 4096 7月 20 22:03 ./drwxr-xr-x 4 root root 4096 7月 20 22:02 ../-rw-r----- 1 root root 0 7月 20 22:03 cocacola_regest.logdrwxr-xr-x 2 root root 4096 7月 20 22:02 console/-rw-r----- 1 root root 0 7月 20 22:03 database-stat.log 这是我们发现文件的权限不对，少了一个任何用户可读的权限，踏上寻找问题的原因： 在linux中，一位用户在创建文件和目录时，对其具有的权限都是一样的，如需更改，需要chmod命令做相应的更改。为什么？其实是权限掩码起作用了。 权限掩码的作用就是规范初创文件和目录时候的权限设置，免去了创建后再次修改权限的问题。因此，权限掩码的设置需要合理。 默认文件写入原理：查看用户的权限掩码命令：umask 12root@192-168-104-194:~# umask0022 创建对应的目录权限 12345678root@192-168-104-194:/tmp# mkdir aaaroot@192-168-104-194:/tmp# touch aroot@192-168-104-194:/tmp# lltotal 44drwxrwxrwt 10 root root 4096 7月 22 15:29 ./drwxr-xr-x 25 root root 4096 7月 5 17:05 ../-rw-r--r-- 1 root root 0 7月 22 15:29 adrwxr-xr-x 2 root root 4096 7月 22 15:29 aaa/ 修改用户的权限掩码 命令：umask abc 备注：对于文件，掩码abc的实际值为偶数值，需要向下减1.① 新创建的文件的权限为：(7-a)(7-b)(7-c) ，如果a/b/c中有一位为0，则相减之后的每位奇数都要减1.② 新创建的目录的权限为：(7-a)(7-b)(7-c) 1234567891011root@192-168-104-194:/tmp# umask 005root@192-168-104-194:/tmp# touch b root@192-168-104-194:/tmp# mkdir bbbroot@192-168-104-194:/tmp# lltotal 48drwxrwxrwt 11 root root 4096 7月 22 15:34 ./drwxr-xr-x 25 root root 4096 7月 5 17:05 ../-rw-r--r-- 1 root root 0 7月 22 15:29 adrwxr-xr-x 2 root root 4096 7月 22 15:29 aaa/-rw-rw--w- 1 root root 0 7月 22 15:33 bdrwxrwx-w- 2 root root 4096 7月 22 15:34 bbb/ 踏上寻找之源检查容器与宿主机的用户所对应的权限： 发现全部为，说明此处没有问题： 12root@192-168-104-194:/tmp# umask0022 尝试在容器中写入创建文件，发现一切正常，映射到主机的权限也是对的，此时我们将焦点聚集到容器服务中。 首先我们检查到了logback的配置文件，其中未找到相关能够配置文件默认权限的地方，但是log4j存在这样的配置。但是同样的代码其他的机器还是都是正常的，这一点我也是没有去尝试。 仔细的查看容器的服务：我到了tomcat的进程：catalina.sh中存在这样的一句话，仿佛找到了救星。 1# UMASK (Optional) Override Tomcat&apos;s default UMASK of 0027 其中文件的具体实现为：123456789# Set UMASK unless it has been overriddenif [ -z &quot;$UMASK&quot; ]; then UMASK=&quot;0027&quot;fiumask $UMASK# Uncomment the following line to make the umask available when using the# org.apache.catalina.security.SecurityListener#JAVA_OPTS=&quot;$JAVA_OPTS -Dorg.apache.catalina.security.SecurityListener.UMASK=`umask`&quot; 按照他的要求我在： K8S的yaml中添加如下的ENV 12- name: UMASK value: &apos;0022&apos; 此时在查看相关的文件权限正确： 12345678total 36drwxr-xr-x 4 root root 4096 7月 22 00:33 ./drwxr-xr-x 3 root root 4096 7月 21 00:32 ../drwxr-xr-x 3 root root 4096 7月 22 00:33 archived/drwxr-xr-x 2 root root 4096 7月 21 00:32 console/-rw-r--r-- 1 root root 0 7月 21 00:32 database-timeout.log-rw-r--r-- 1 root root 8416 7月 22 15:33 debug-log.log-rw-r--r-- 1 root root 0 7月 21 00:32 redisSelectUser.log","categories":[],"tags":[{"name":"devops","slug":"devops","permalink":"https://banghuaji.github.io/tags/devops/"},{"name":"docker","slug":"docker","permalink":"https://banghuaji.github.io/tags/docker/"}]},{"title":"虚拟机与Docker有何不同","slug":"docker/虚拟机与Docker有何不同","date":"2018-06-20T15:49:26.763Z","updated":"2018-06-20T15:48:54.342Z","comments":true,"path":"2018/06/20/docker/虚拟机与Docker有何不同/","link":"","permalink":"https://banghuaji.github.io/2018/06/20/docker/虚拟机与Docker有何不同/","excerpt":"","text":"最近大家总是咨询虚拟机与VM的不同，这里从网上查找简单的一些资料进行说明。 首先，大家需要明确一点，Docker容器不是虚拟机。 2014年，当我第一次接触Docker的时候，我把它比做一种轻量级的虚拟机。这样做无可厚非，因为Docker最初的成功秘诀，正是它比虚拟机更节省内存，启动更快。Docker不停地给大家宣传，”虚拟机需要数分钟启动，而Docker容器只需要50毫秒”。 然而，Docker容器并非虚拟机，我们不妨来比较一下它们。 理解虚拟机使用虚拟机运行多个相互隔离的应用时，如下图: 从下到上理解上图: 基础设施(Infrastructure)。它可以是你的个人电脑，数据中心的服务器，或者是云主机。 主操作系统(Host Operating System)。你的个人电脑之上，运行的可能是MacOS，Windows或者某个Linux发行版。 虚拟机管理系统(Hypervisor)。利用Hypervisor，可以在主操作系统之上运行多个不同的从操作系统。类型1的Hypervisor有支持MacOS的HyperKit，支持Windows的Hyper-V以及支持Linux的KVM。类型2的Hypervisor有VirtualBox和VMWare。 从操作系统(Guest Operating System)。假设你需要运行3个相互隔离的应用，则需要使用Hypervisor启动3个从操作系统，也就是3个虚拟机。这些虚拟机都非常大，也许有700MB，这就意味着它们将占用2.1GB的磁盘空间。更糟糕的是，它们还会消耗很多CPU和内存。 各种依赖。每一个从操作系统都需要安装许多依赖。如果你的的应用需要连接PostgreSQL的话，则需要安装libpq-dev；如果你使用Ruby的话，应该需要安装gems；如果使用其他编程语言，比如Python或者Node.js，都会需要安装对应的依赖库。 应用。安装依赖之后，就可以在各个从操作系统分别运行应用了，这样各个应用就是相互隔离的。 理解Docker容器使用Docker容器运行多个相互隔离的应用时，如下图: 不难发现，相比于虚拟机，Docker要简洁很多。因为我们不需要运行一个臃肿的从操作系统了。 从下到上理解上图: 基础设施(Infrastructure)。 主操作系统(Host Operating System)。所有主流的Linux发行版都可以运行Docker。对于MacOS和Windows，也有一些办法”运行”Docker。 Docker守护进程(Docker Daemon)。Docker守护进程取代了Hypervisor，它是运行在操作系统之上的后台进程，负责管理Docker容器。 各种依赖。对于Docker，应用的所有依赖都打包在Docker镜像中，Docker容器是基于Docker镜像创建的。 应用。应用的源代码与它的依赖都打包在Docker镜像中，不同的应用需要不同的Docker镜像。不同的应用运行在不同的Docker容器中，它们是相互隔离的。 对比虚拟机与DockerDocker守护进程可以直接与主操作系统进行通信，为各个Docker容器分配资源；它还可以将容器与主操作系统隔离，并将各个容器互相隔离。虚拟机启动需要数分钟，而Docker容器可以在数毫秒内启动。由于没有臃肿的从操作系统，Docker可以节省大量的磁盘空间以及其他系统资源。 说了这么多Docker的优势，大家也没有必要完全否定虚拟机技术，因为两者有不同的使用场景。虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而Docker通常用于隔离不同的应用，例如前端，后端以及数据库。","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"}]},{"title":"shadowsocks-Server","slug":"deploy/shadowsocket-privoxy/Shadowsocks-privoxy","date":"2018-05-28T13:06:33.616Z","updated":"2018-05-27T04:36:22.000Z","comments":true,"path":"2018/05/28/deploy/shadowsocket-privoxy/Shadowsocks-privoxy/","link":"","permalink":"https://banghuaji.github.io/2018/05/28/deploy/shadowsocket-privoxy/Shadowsocks-privoxy/","excerpt":"","text":"安装shadowsocks Server：本例以shadowsocks-libev 为说明，shadowsocks其他安装方式，可参考官方 2.1下载repo文件到/etc/yum.repos.d/2.2使用yum安装：12yum updateyum install shadowsocks-libev 配置shadowsocks1vi /etc/shadowsocks/config.json 内容如下： 123456789101112131415&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:8388, // 服务器端口 &quot;local_port&quot;:1080, &quot;password&quot;:&quot;12345678&quot;, // 认证密码，此处请以个人口味修改 &quot;timeout&quot;:600, &quot;method&quot;:&quot;aes-256-cfb&quot; // 加密方式，推荐使用aes-256-cfb&#125; 重启shadowsocks服务123/etc/init.d/shadowsocks stop /etc/init.d/shadowsocks start 客户端下载外部链接 privoxy有将socks代理转为http代理的功能。 Shadowsocks是 socks5的代理，我们的http请求需要通过Privoxy把socks5转成http代理 1.开启shadowsocks，socks代理地址为127.0.0.1:1080。 2.安装privoxy。 1$ sudo apt-get install privoxy 3.更改provoxy配置，位置在“/etc/privoxy/config”。 $ sudo vim /etc/privoxy/config在里面添加一条： 12345678910# 在 froward-socks4下面添加一条socks5的，因为shadowsocks为socks5，# 地址是127.0.0.1:1080。注意他们最后有一个“.”# forward-socks4 / socks-gw.example.com:1080 .forward-socks5 / 127.0.0.1:1080 .# 下面还存在以下一条配置，表示privoxy监听本机8118端口，# 把它作为http代理，代理地址为 http://localhost.8118/ 。# 可以把地址改为 0.0.0.0:8118，表示外网也可以通过本机IP作http代理。# 这样，你的外网IP为1.2.3.4，别人就可以设置 http://1.2.3.4:8118/ 为http代理。 listen-address localhost:8118 4.然后重启privoxy。 1$ sudo systemctl restart privoxy.serivce 5.现在你就可以使用http代理了，如果你要给系统设置http代理，就在~/.bashrc里添加一条http_proxy配置。 1234567$ vim ~/.bashrc添加：export http_proxy=http://127.0.0.1:8118/然后使用source是它立刻生效。$ source ~/.bashrc","categories":[],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://banghuaji.github.io/tags/LINUX/"}]},{"title":"Dockerfile--CMD&&ENTRYPOINT","slug":"docker/Dockerfile-CMD与ENTRYPOINT","date":"2018-04-20T14:27:34.247Z","updated":"2018-04-20T14:27:07.000Z","comments":true,"path":"2018/04/20/docker/Dockerfile-CMD与ENTRYPOINT/","link":"","permalink":"https://banghuaji.github.io/2018/04/20/docker/Dockerfile-CMD与ENTRYPOINT/","excerpt":"","text":"今天在自己的机器上测试了一下ENTRYPOINT与CMD的使用方法 相同点： 均支持两种运行的方式，取于官方文档， 12ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form, preferred)ENTRYPOINT command param1 param2 (shell form) 123CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec form, this is the preferred form)CMD [&quot;param1&quot;,&quot;param2&quot;] (as default parameters to ENTRYPOINT)CMD command param1 param2 (shell form) 不同点：- CMD 的命令可以被docker run覆盖ENTRYPOINT则不行，且ENTRYPOINT可接收CMD的参数，这时ENTRYPOINT也是有要求的ENTRYPOINT必须使用exec form的格式。1234这种可以以参数的形式增加：#ENTRYPOINT [ &quot;echo&quot;, &quot;a&quot;, &quot;http://ip.cn&quot; ] para add且CMD [&quot;param1&quot;,&quot;param2&quot;] - 若是CMD param1 param2样式：则无法成功 以下的形式均不可增加：无论CMD以何种形式展示：123#ENTRYPOINT echo java CMD para do not add#ENTRYPOINT [&quot;sh&quot;,&quot;-c&quot;,&quot;eval echo java&quot;]#ENTRYPOINT [ &quot;echo&quot;, &quot;a&quot;] 若是执行的命令中存在SHELL中的$HOME如下则必须使用 shell脚本的方式：如下：123CMD exec java -Xmx$XMX -Xms$XMS -jar /home/javaopts.jarENTRYPOINT exec java -Xmx$XMX -Xms$XMS -jar /home/javaopts.jar 是否可以考虑其他的模式：12345678910#默认启动的jar包为javaopts.jarENTRYPOINT [&quot;/home/entrypoint.sh&quot;]entrypoint的脚本为：#!/bin/bashecho JAVA_OPTS=$JAVA_OPTSexec java -Xmx$XMX -Xms$XMS -jar $1CMD中传入参数：CMD [&quot;/home/javaopts.jar&quot;] 如上可以考虑docker hub官网redis的实现。 得出如下的结论：优先使用CMD若是存在麻烦则可以使用entrypoint来增加参数若是需要增加参数必须使用shell的模式来完成，","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"}]},{"title":"Java的SystemInfoUtil类","slug":"language/java/Java的SystemInfoUtil","date":"2018-02-24T12:48:11.789Z","updated":"2018-02-24T09:58:07.000Z","comments":true,"path":"2018/02/24/language/java/Java的SystemInfoUtil/","link":"","permalink":"https://banghuaji.github.io/2018/02/24/language/java/Java的SystemInfoUtil/","excerpt":"","text":"之前的同事给的一个例子，主要能够获取运行机器的信息 在做自动化方面体现比较重要，今天贴出来查看下。 获取系统信息以及服务器信息，由于样式比较的多，出来的效果不是很好查看，请允许我在这边写一些废话 123456789101112131415161718192021222324252627282930313233/** * 项目信息 * * @return */protected Map getProjectInfo() &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); Properties props = new Properties(); try &#123; /** * 从配置文件中获取相关网站信息 */ props.load(SystemInfoUtil.class.getClassLoader().getResourceAsStream(\"common.properties\")); &#125; catch (IOException e) &#123; logger.error(\"IOException\", e); &#125; /** * 项目版本 */ map.put(\"project_version\",props.getProperty(\"project.version\")); /** * 项目编码 */ map.put(\"project_build_sourceEncoding\",props.getProperty(\"project.build.sourceEncoding\")); SimpleDateFormat time=new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); /** * 项目启动日期 */ map.put(\"start_date\",time.format(new Date())); return map;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.lang.reflect.Method;import java.net.InetAddress;import java.net.UnknownHostException;import java.sql.Connection;import java.sql.DatabaseMetaData;import java.sql.DriverManager;import java.text.SimpleDateFormat;import java.util.Date;import java.util.HashMap;import java.util.Locale;import java.util.Map;import java.util.Properties;import java.util.logging.SimpleFormatter;public class SystemInfoUtil &#123; private static Logger logger = LoggerFactory.getLogger(SystemInfoUtil.class); /** * 服务器环境相关信息 * * @return */ public Map getSystemInfo() &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); /** * java.version Java 运行时环境版本 */ map.put(\"java_version\", System.getProperty(\"java.version\")); /** * java.vendor Java 运行时环境供应商 */ map.put(\"java_vendor\", System.getProperty(\"java.vendor\")); /** * java.vendor.url Java 供应商的 URL */ map.put(\"java_vendor_url\", System.getProperty(\"java.vendor.url\")); /** * java.home Java 安装目录 */ map.put(\"java_home\", System.getProperty(\"java.home\")); /** * java.vm.specification.version Java 虚拟机规范版本 */ map.put(\"java_vm_specification_version\", System.getProperty(\"java.vm.specification.version\")); /** * java.vm.specification.vendor Java 虚拟机规范供应 */ map.put(\"java_vm_specification_vendor\", System.getProperty(\"java.vm.specification.vendor\")); /** * java.vm.specification.name Java 虚拟机规范名称 */ map.put(\"java_vm_specification_name\", System.getProperty(\"java.vm.specification.name\")); /** * java.vm.version Java 虚拟机实现版本 */ map.put(\"java_vm_version\", System.getProperty(\"java.vm.version\")); /** * java.vm.vendor Java 虚拟机实现供应商 */ map.put(\"java_vm_vendor\", System.getProperty(\"java.vm.vendor\")); /** * java.vm.name Java 虚拟机实现名称 */ map.put(\"java_vm_name\", System.getProperty(\"java.vm.name\")); /** * java.specification.version Java 运行时环境规范版本 */ map.put(\"java_specification_version\", System.getProperty(\"java.specification.version\")); /** * java.specification.vendor Java 运行时环境规范供应商 */ map.put(\"java_specification_vendor\", System.getProperty(\"java.specification.vendor\")); /** * java.specification.name Java 运行时环境规范名称 */ map.put(\"java_specification_name\", System.getProperty(\"java.specification.name\")); /** * java.class.version Java 类格式版本号 */ map.put(\"java_class_version\", System.getProperty(\"java.class.version\")); /** * java.class.path Java 类路径 */ map.put(\"java_class_path\", System.getProperty(\"java.class.path\")); /** * java.library.path 加载库时搜索的路径列表 */ map.put(\"java_library_path\", System.getProperty(\"java.library.path\")); /** * java.io.tmpdir 默认的临时文件路径 */ map.put(\"java_io_tmpdir\", System.getProperty(\"java.io.tmpdir\")); /** * java.compiler 要使用的 JIT 编译器的名称 */ map.put(\"java_compiler\", System.getProperty(\"java.compiler\")); /** * java.ext.dirs 一个或多个扩展目录的路径 */ map.put(\"java_ext_dirs\", System.getProperty(\"java.ext.dirs\")); /** * os.name 操作系统的名称 */ map.put(\"os_name\", System.getProperty(\"os.name\")); /** * os.arch 操作系统的架构 */ map.put(\"os_arch\", System.getProperty(\"os.arch\")); /** * os.version 操作系统的版本 */ map.put(\"os_version\", System.getProperty(\"os.version\")); /** * file.separator 文件分隔符（在 UNIX 系统中是“/”） */ map.put(\"file_separator\", System.getProperty(\"file.separator\")); /** * path.separator 路径分隔符（在 UNIX 系统中是“:”） */ map.put(\"path_separator\", System.getProperty(\"path.separator\")); /** * line.separator 行分隔符（在 UNIX 系统中是“/n”） */ map.put(\"line_separator\", System.getProperty(\"line.separator\")); /** * user.name 用户的账户名称 */ map.put(\"user_name\", System.getProperty(\"user.name\")); /** * user.home 用户的主目录 */ map.put(\"user_home\", System.getProperty(\"user.home\")); /** * user.dir 用户的当前工作目录 */ map.put(\"user_dir\", System.getProperty(\"user.dir\")); /** * file_encoding 获取JVM编码格式 */ map.put(\"file_encoding\", System.getProperty(\"file.encoding\")); /** * 获取操作系统的编码 */ map.put(\"sun_jnu_encoding\", System.getProperty(\"sun.jnu.encoding\")); InetAddress netAddress = getInetAddress(); /** * host_ip 获取本地IP */ map.put(\"host_ip\", getHostIp(netAddress)); /** * host_name 获取本地主机名 */ map.put(\"host_name\", getHostName(netAddress)); Locale locale = Locale.getDefault(); /** * language 获取语言 */ map.put(\"language\",locale.getLanguage()); /** * country 获取语言国家 */ map.put(\"country\",locale.getCountry()); return map; &#125; /** * 获取本地主机 * * @return */ public static InetAddress getInetAddress() &#123; try &#123; return InetAddress.getLocalHost(); &#125; catch (UnknownHostException e) &#123; logger.error(\"UnknownHostException\", e); &#125; return null; &#125; /** * 通过InetAddress获取本地Ip * * @param netAddress * @return */ public static String getHostIp(InetAddress netAddress) &#123; if (null == netAddress) &#123; return null; &#125; String ip = netAddress.getHostAddress(); return ip; &#125; /** * 通过InetAddress获取本地主机的名字 * * @param netAddress * @return */ public static String getHostName(InetAddress netAddress) &#123; if (null == netAddress) &#123; return null; &#125; String name = netAddress.getHostName(); return name; &#125; /** * 通过Jdbc的方式获取数据库的版本 * * @return */ protected Map getDatabaseMajorVersion() &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); PropertyUtil propertyUtil = new PropertyUtil(); Properties props = new Properties(); try &#123; /** * 从配置文件读取 链接数据库信息 * 然后建立连接 * 用适当的驱动程序连接到DBMS，看下面的代码[自行修改您所连接的数据库相关信息]： */ props.load(SystemInfoUtil.class.getClassLoader().getResourceAsStream(\"jdbc.properties\")); String url = props.getProperty(\"jdbcUrl\"); String user = props.getProperty(\"username\"); String password = props.getProperty(\"password\"); String driver = props.getProperty(\"driverClasss\"); // 加载驱动程序 // 下面的代码为加载JDBD-ODBC驱动程序 Class.forName(driver); // 用url创建连接 Connection con = DriverManager.getConnection(url, user, password); // 获取数据库的信息 DatabaseMetaData dbMetaData = con.getMetaData(); /** * 返回一个String类对象，代表数据库的URL */ map.put(\"URL\", dbMetaData.getURL()); /** * 返回连接当前数据库管理系统的用户名。 */ map.put(\"userName\", dbMetaData.getUserName()); /** * 返回一个boolean值，指示数据库是否只允许读操作。 */ map.put(\"isReadOnly\", dbMetaData.isReadOnly() + \"\"); /** * 返回数据库的产品名称。 */ map.put(\"DatabaseProductName\", dbMetaData.getDatabaseProductName()); /** * 返回数据库的版本号。 */ map.put(\"DatabaseProductVersion\", dbMetaData.getDatabaseProductVersion()); Method gdbmvMethod = DatabaseMetaData.class.getMethod(\"getDatabaseMajorVersion\", null); /** * 数据库真正的版本号 */ map.put(\"version\", gdbmvMethod.invoke(dbMetaData, null)+\"\"); /** * 返回驱动驱动程序的名称。 */ map.put(\"DriverName\", dbMetaData.getDriverName()); /** * 返回驱动程序的版本号。 */ map.put(\"DriverVersion\", dbMetaData.getDriverVersion()); // 关闭连接 con.close(); &#125; catch (Exception e) &#123; // 输出异常信息 logger.error(\"Exception\", e); &#125; return map; &#125; /** * 项目信息 * * @return */ protected Map getProjectInfo() &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); Properties props = new Properties(); try &#123; /** * 从配置文件中获取相关网站信息 */ props.load(SystemInfoUtil.class.getClassLoader().getResourceAsStream(\"common.properties\")); &#125; catch (IOException e) &#123; logger.error(\"IOException\", e); &#125; /** * 项目版本 */ map.put(\"project_version\",props.getProperty(\"project.version\")); /** * 项目编码 */ map.put(\"project_build_sourceEncoding\",props.getProperty(\"project.build.sourceEncoding\")); SimpleDateFormat time=new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); /** * 项目启动日期 */ map.put(\"start_date\",time.format(new Date())); return map; &#125;&#125;","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://banghuaji.github.io/tags/JAVA/"}]},{"title":"jarjar解决jar冲突问题","slug":"soft/jarjar解决jar冲突问题","date":"2018-02-23T13:09:20.651Z","updated":"2018-02-23T10:01:05.000Z","comments":true,"path":"2018/02/23/soft/jarjar解决jar冲突问题/","link":"","permalink":"https://banghuaji.github.io/2018/02/23/soft/jarjar解决jar冲突问题/","excerpt":"","text":"一个项目里面同一个jar包一般不能有两个版本的 不然可能会出现jar包冲突的情况常见报错有这三个： java.lang.ClassNotFoundException(找不到类) java.lang.NoSuchMethodError(找不到具体方法) java.lang.NoSuchFieldError(字段错误) java.lang.LinkageError(类错误 这个我没怎么见过) 解决思路： 删了旧版本的jar包，不过可能会导致一些旧代码不能用 （不推荐） 合并新旧两个jar包，这个有比较高的技术要求（不会） 拆开jar包，修改里面的package，然后在生成一个新的jar包（方便，简单，如果遇到需要就该jar包内容的情况，这个方法也适用）。 解决方法：1、首先下载jarjar.jar ： 12官网：https://code.google.com/p/jarjar/（要翻墙）附件：http://download.csdn.net/detail/qq_22778717/9689007 2、随便放一个地方（我放到E盘的jarjar文件夹下） 3、打开cmd，cd到E盘的jarjar文件夹，然后就运行jarjar.jar（如图1、2两个步骤）这里写图片描述 4、打开一个txt 输入rule org.apache.http.** org.apache.http123.@1来设置转换规则，并且存到jarjar文件夹下 （格式就这样：rule xxxx.xx.aaa.** xxxx.xx.aaa123.@1）修改的地方就是aaa那里 5、把需要转换的 xxxxx1.jar放到jarjar文件夹里面，然后输入java -jar jarjar.jar strings xxxxx1.jar，查看你要修改的jar包的包名 6、输入java -jar jarjar.jar process ./aa.txt xxxxx1.jar ./xxxxx2.jar开始转换(xxxxx1.jar是需要被修改路径的jar包 xxxxx2.jar是修改后生成jar包的名字) 这里写图片描述 到这里 看到红线下面那个E：\\jarjar&gt; 就代表整个步骤完成了，可以去jarjar文件夹看一下你新的jar包，这个jar包导入项目的时候也不用担心说冲突了。","categories":[],"tags":[{"name":"软件","slug":"软件","permalink":"https://banghuaji.github.io/tags/软件/"},{"name":"jar","slug":"jar","permalink":"https://banghuaji.github.io/tags/jar/"}]},{"title":"Shell编程之判断","slug":"linux/Shell编程之判断","date":"2018-01-26T14:39:01.688Z","updated":"2018-01-26T07:52:45.000Z","comments":true,"path":"2018/01/26/linux/Shell编程之判断/","link":"","permalink":"https://banghuaji.github.io/2018/01/26/linux/Shell编程之判断/","excerpt":"","text":"一、if的基本语法:1234567if [ command ];then 符合该条件执行的语句elif [ command ];then 符合该条件执行的语句else 符合该条件执行的语句fi 二、文件/文件夹(目录)判断12345678910111213141516171819202122[ -b FILE ] 如果 FILE 存在且是一个块特殊文件则为真。[ -c FILE ] 如果 FILE 存在且是一个字特殊文件则为真。[ -d DIR ] 如果 FILE 存在且是一个目录则为真。[ -e FILE ] 如果 FILE 存在则为真。[ -f FILE ] 如果 FILE 存在且是一个普通文件则为真。[ -g FILE ] 如果 FILE 存在且已经设置了SGID则为真。[ -k FILE ] 如果 FILE 存在且已经设置了粘制位则为真。[ -p FILE ] 如果 FILE 存在且是一个名字管道(F如果O)则为真。[ -r FILE ] 如果 FILE 存在且是可读的则为真。[ -s FILE ] 如果 FILE 存在且大小不为0则为真。[ -t FD ] 如果文件描述符 FD 打开且指向一个终端则为真。[ -u FILE ] 如果 FILE 存在且设置了SUID (set user ID)则为真。[ -w FILE ] 如果 FILE存在且是可写的则为真。[ -x FILE ] 如果 FILE 存在且是可执行的则为真。[ -O FILE ] 如果 FILE 存在且属有效用户ID则为真。[ -G FILE ] 如果 FILE 存在且属有效用户组则为真。[ -L FILE ] 如果 FILE 存在且是一个符号连接则为真。[ -N FILE ] 如果 FILE 存在 and has been mod如果ied since it was last read则为真。[ -S FILE ] 如果 FILE 存在且是一个套接字则为真。[ FILE1 -nt FILE2 ] 如果 FILE1 has been changed more recently than FILE2, or 如果 FILE1 exists and FILE2 does not则为真。[ FILE1 -ot FILE2 ] 如果 FILE1 比 FILE2 要老, 或者 FILE2 存在且 FILE1 不存在则为真。[ FILE1 -ef FILE2 ] 如果 FILE1 和 FILE2 指向相同的设备和节点号则为真。 三、字符串判断12345[ -z STRING ] 如果STRING的长度为零则为真 ，即判断是否为空，空即是真；[ -n STRING ] 如果STRING的长度非零则为真 ，即判断是否为非空，非空即是真；[ STRING1 = STRING2 ] 如果两个字符串相同则为真 ；[ STRING1 != STRING2 ] 如果字符串不相同则为真 ；[ STRING1 ] 如果字符串不为空则为真,与-n类似 四、数值判断123456INT1 -eq INT2 INT1和INT2两数相等为真 ,=INT1 -ne INT2 INT1和INT2两数不等为真 ,&lt;&gt;INT1 -gt INT2 INT1大于INT1为真 ,&gt;INT1 -ge INT2 INT1大于等于INT2为真,&gt;=INT1 -lt INT2 INT1小于INT2为真 ,&lt;&lt;/div&gt;INT1 -le INT2 INT1小于等于INT2为真,&lt;= 五、复杂逻辑判断12345678910111213141516171819-a 与-o 或! 非exp1: 如果a&gt;b且aif (( a &gt; b )) &amp;&amp; (( a &lt; c ))或者if [[ $a &gt; $b ]] &amp;&amp; [[ $a &lt; $c ]]或者if [ $a -gt $b -a $a -lt $c ]exp2:如果a&gt;b或aif (( a &gt; b )) || (( a &lt; c ))或者if [[ $a &gt; $b ]] || [[ $a &lt; $c ]]或者if [ $a -gt $b -o $a -lt $c ] &quot;||&quot;和&quot;&amp;&amp;&quot;在SHELL里可以用，也就是第一个写成if [ a&gt;b &amp;&amp; a","categories":[],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://banghuaji.github.io/tags/LINUX/"}]},{"title":"Shell编程之变量","slug":"linux/Shell编程之变量","date":"2018-01-26T14:39:01.622Z","updated":"2018-01-26T07:53:17.000Z","comments":true,"path":"2018/01/26/linux/Shell编程之变量/","link":"","permalink":"https://banghuaji.github.io/2018/01/26/linux/Shell编程之变量/","excerpt":"","text":"Bash变量与变量分类Bash是Linux中的标准Shell，因此经常称Bash为Shell。 1. 变量命名规则 变量名可以由字母、数字、下划线组成，但必须以字母与下划线开头； 变量名的长度不能超过255个字符； 变量名在有效范围必须唯一； 在Bash中，变量的默认类型都字符串型； 2. 变量按照存储类型分类默认类型是字符串型。 字符串型，赋值时单双引号皆可； 整形； 12345678910#默认类型是字符串型。M=45+20echo $M #整形计算A=15 B=30declare -i C=$A+$BD=$A+$Becho C=$C, D=$D #输出为：C=45, D=15+30 浮点型； 123456789101112131415161718192021221、借助bc处理示例：计算5.01-4*2.0，得到的结果为-2.99$ c=$(echo &quot;5.01-4*2.0&quot;|bc)$ echo $c2、借助awk处理示例：计算7.01*5-4.01，得到的结果为31.05$ c=$(awk &apos;BEGIN&#123;print 7.01*5-4.01 &#125;&apos;)$ echo $c注：在shell 中$() 与 ``等效。 中间包含命令语句执行，返回执行结果。a=3.33b=3.3c=$(echo &quot;$a + $b&quot; | bc)d=$(echo &quot;$a * $b&quot; | bc)echo $cecho $df=`echo &quot;$c * $d&quot; | bc`echo $f 浮点型与整形的比较 12345678910111213下面是一个常规写法的示例：if [ 1.1 -gt 1 ];then echo &quot;OK&quot;fi直接会抛出如下异常：line 3: [: 1.1: integer expression expected正确的写法如下：if [ `echo &quot;1.1 &gt; 1&quot; | bc` -eq 1 ];then echo &quot;OK&quot;fi 日期型； 1234567891011121314151617181920212223242526272829303132333435获取今天时期：`date +%Y%m%d` 或 `date +%F` 或 $(date +%y%m%d) 获取昨天时期：`date -d yesterday +%Y%m%d` 获取前天日期：`date -d -2day +%Y%m%d` 依次类推比如获取10天前的日期：`date -d -10day +%Y%m%d` 或n天前的 `date -d &quot;n days ago&quot; +%y%m%d` 明天：`date -d tomorrow +%y%m%d` 注意以上中间有空格 时间域 % H 小时（00..23） % I 小时（01..12） % k 小时（0..23） % l 小时（1..12） % M 分（00..59） % p 显示出AM或PM % r 时间（hh：mm：ss AM或PM），12小时 % s 从1970年1月1日00：00：00到目前经历的秒数 % S 秒（00..59） % T 时间（24小时制）（hh:mm:ss） % X 显示时间的格式（％H:％M:％S） % Z 时区 日期域 % a 星期几的简称（ Sun..Sat） % A 星期几的全称（ Sunday..Saturday） % b 月的简称（Jan..Dec） % B 月的全称（January..December） % c 日期和时间（ Mon Nov 8 14：12：46 CST 1999） % d 一个月的第几天（01..31） % D 日期（mm／dd／yy） % h 和%b选项相同 % j 一年的第几天（001..366） % m 月（01..12） % w 一个星期的第几天（0代表星期天） % W 一年的第几个星期（00..53，星期一为第一天） % x 显示日期的格式（mm/dd/yy） % y 年的最后两个数字（ 1999则是99） % Y 年（例如：1970，1996等） 位置参数变量 shell中$*与$@的区别“$@”必须被引用. $@ $ 只在被双引号包起来的时候才会有差异双引号括起来的情况：$将所有的参数认为是一个字段$@以IFS（默认为空格）来划分字段，如果空格在“”里面，不划分。采用LS的脚本运行./test 1 “2 3” 4 来发现差异 例子：12345678910111213141516171819202122232425262728293031323334#脚本如下 #!/bin/bashecho $2echo $*echo $@echo $#index=1echo &quot;Listing args with \\&quot;\\$@\\&quot;:&quot;for arg in &quot;$@&quot;doecho &quot;Arg #$index=$arg&quot;let &quot;index+=1&quot;doneindex=1echo &quot;Listing args with \\&quot;\\$*\\&quot;:&quot;for arg in &quot;$*&quot;doecho &quot;Arg #$index=$arg&quot;let &quot;index+=1&quot;doneecho &quot;以下没有引号&quot;index=1echo &quot;Listing args with \\$*:&quot;for arg in $*doecho &quot;Arg #$index=$arg&quot; 输出结果：./a.sh a b c d e f g12345678910111213141516171819202122232425262728293031ba b c d e f ga b c d e f g7Listing args with &quot;$@&quot;:Arg #1=aArg #2=bArg #3=cArg #4=dArg #5=eArg #6=fArg #7=gListing args with &quot;$*&quot;:Arg #1=a b c d e f g以下没有引号Listing args with $*:Arg #1=aArg #2=bArg #3=cArg #4=dArg #5=eArg #6=fArg #7=gListing args with $@Arg #1=aArg #2=bArg #3=cArg #4=dArg #5=eArg #6=fArg #7=g","categories":[],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://banghuaji.github.io/tags/LINUX/"}]},{"title":"Linux中修改环境变量及生效方法","slug":"linux/Linux中修改环境变量及生效方法","date":"2018-01-24T13:23:59.486Z","updated":"2018-01-24T03:27:53.000Z","comments":true,"path":"2018/01/24/linux/Linux中修改环境变量及生效方法/","link":"","permalink":"https://banghuaji.github.io/2018/01/24/linux/Linux中修改环境变量及生效方法/","excerpt":"","text":"方法一： 在/etc/profile文件中添加变量【对所有用户生效(永久的)】 用VI在文件/etc/profile文件中增加变量，该变量将会对Linux下所有用户有效，并且是“永久的”。 要让刚才的修改马上生效，需要执行以下代码 1# source /etc/profile 方法二： 在用户目录下的.bash_profile文件中增加变量【对单一用户生效(永久的)】 用VI在用户目录下的.bash_profile文件中增加变量，改变量仅会对当前用户有效，并且是“永久的”。 要让刚才的修改马上生效，需要在用户目录下执行以下代码 1# source .bash_profile 方法三 直接运行export命令定义变量【只对当前shell(BASH)有效(临时的)】 在shell的命令行下直接使用[export变量名=变量值]定义变量，该变量只在当前的shell(BASH)或其子shell(BASH)下是有效的，shell关闭了，变量也就失效了，再打开新shell时就没有这个变量，需要使用的话还需要重新定义。 1例如：export PATH=/usr/local/webserver/php/bin:$PATH","categories":[],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://banghuaji.github.io/tags/LINUX/"}]},{"title":"Tomcat中JVM内存溢出及合理配置","slug":"language/java/Tomcat中JVM内存溢出及合理配置","date":"2017-12-24T07:10:25.918Z","updated":"2017-12-24T07:10:20.000Z","comments":true,"path":"2017/12/24/language/java/Tomcat中JVM内存溢出及合理配置/","link":"","permalink":"https://banghuaji.github.io/2017/12/24/language/java/Tomcat中JVM内存溢出及合理配置/","excerpt":"","text":"最近学习DOCKR技术，在配置TOMCAT的时候发现要配置Xms，Xmx相关的参数，进而优化DOCKER的性能 JVM内存分配设置的参数有四个12345678910111213141516-Xmx Java Heap最大值，默认值为物理内存的1/4；-Xms Java Heap初始值，Server端JVM最好将-Xms和-Xmx设为相同值，开发测试机JVM可以保留默认值；-Xmn Java Heap Young区大小，不熟悉最好保留默认值；-Xss 每个线程的Stack大小，不熟悉最好保留默认值；-XX:PermSize：设定内存的永久保存区域； -XX:MaxPermSize：设定最大内存的永久保存区域；-XX:PermSize：设定内存的永久保存区域；-XX:NewSize：设置JVM堆的‘新生代’的默认大小；-XX:MaxNewSize：设置JVM堆的‘新生代’的最大大小； 当在服务器环境下（如Tomcat）启动并使用JVM时（对当前服务器环境下所以Java程序生效）：123JAVA_OPTS=&quot;-server -Xms800m -Xmx800m -XX:PermSize=64M -XX:MaxNewSize=256m -XX:MaxPermSize=128m -Djava.awt.headless=true &quot;java -Xms64m -Xmx256m Test -Xms是设置内存初始化的大小 -Xmx是设置最大能够使用内存的大小。 Java JVM内存介绍JVM管理两种类型的内存，堆和非堆。堆：Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的 在JVM中堆之外的内存称为非堆内存(Non-heap memory)（当然JAVA8中此处已经改为采用机器的元内存）简单来说堆就是Java代码可及的内存，是留给开发人员使用的；非堆就是JVM留给自己用的，所以方法区、JVM内部处理或优化所需的内存(如JIT编译后的代码缓存)、每个类结构(如运行时常数池、字段和方法数据)以及方法和构造方法的代码都在非堆内存中，它和堆不同，运行期内GC不会释放其空间。 堆内存分配默认设置JVM初始分配的内存由-Xms指定，默认是物理内存的1/64；JVM最大分配的内存由-Xmx指 定，默认是物理内存的1/4。默认空余堆内存小于 40%时，JVM就会增大堆直到-Xmx的最大限制；空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、 -Xmx相等以避免在每次GC 后调整堆的大小 可以利用JVM提供的-Xmn -Xms -Xmx等选项可进行堆内存设置，一般的要将-Xms和-Xmx选项设置为相同，而-Xmn为1/4的-Xmx值，建议堆的最大值设置为可用内存的最大值的80%。 非堆内存分配也叫永久保存的区域，用于存放Class和Meta信息,Class在被Load的时候被放入该区域。它和存放类实例(Instance)的Heap区域不同,GC(Garbage Collection)不会在主程序运行期对PermGen space进行清理。JVM使用-XX:PermSize设置非堆内存初始值，默认是物理内存的1/64；由XX:MaxPermSize设置最大非堆内存的大小，默认是物理内存的1/4。 GC不会对PermGen space进行清理，所以如果你的APP会LOAD很多CLASS的话,就很可能出现PermGen space错误。 JVM内存限制(最大值)首先JVM内存限制于实际的最大物理内存（废话！，呵呵），假设物理内存无限大的话，JVM内存的最大值跟操作系统有很大的关系。简单的说就32位处理器虽然可控内存空间有4GB,但是具体的操作系统会给一个限制，这个限制一般是2GB-3GB（一般来说Windows系统下为1.5G-2G，Linux系统 下为2G-3G），而64bit以上的处理器就不会有限制了。 三种内存溢出异常介绍OutOfMemoryError： Java heap space 堆溢出内存溢出主要存在问题就是出现在这个情况中。当在JVM中如果98％的时间是用于GC且可用的 Heap size 不足2％的时候将抛出此异常信息。 OutOfMemoryError： PermGen space 非堆溢出（永久保存区域溢出）这种错误常见在web服务器对JSP进行pre compile的时候。如果你的WEB APP下都用了大量的第三方jar, 其大小超过了jvm默认的大小(4M)那么就会产生此错误信息了。如果web app用了大量的第三方jar或者应用有太多的class文件而恰好MaxPermSize设置较小，超出了也会导致这块内存的占用过多造成溢出，或者tomcat热部署时侯不会清理前面加载的环境，只会将context更改为新部署的，非堆存的内容就会越来越多。 OutOfMemoryError： unable to create new native thread. 无法创建新的线程这种现象比较少见，也比较奇怪，主要是和jvm与系统内存的比例有关。这种怪事是因为JVM已经被系统分配了大量的内存（比如1.5G），并且它至少要占用可用内存的一半。 JVM内存配置与GC（相辅相成的工作）需要考虑的是Java提供的垃圾回收机制。JVM的堆大小决定了JVM花费在收集垃圾上的时间和频度。收集垃圾可以接受的速度与应用有关，应该通过分析实际的垃圾收集的时间和频率来调整。如果堆的大小很大，那么完全垃圾收集就会很慢，但是频度会降低。如果你把堆的大小和内存的需要一致，完全收集就很快，但是会更加频繁。调整堆大小的的目的是最小化垃圾收集的时间，以在特定的时间内最大化处理客户的请求。在基准测试的时候，为保证最好的性能，要把堆的大小设大，保证垃圾收集不在整个基准测试的过程中出现。如果系统花费很多的时间收集垃圾，请减小堆大小。一次完全的垃圾收集应该不超过 3-5 秒。如果垃圾收集成为瓶颈，那么需要指定堆的大小，检查垃圾收集的详细输出，研究垃圾收集参数对性能的影响。一般说来，你应该使用物理内存的 80% 作为堆大小。当增加处理器时，记得增加内存，因为分配可以并行进行，而垃圾收集不是并行的。 Java Heap分为3个区： 1.Young 2.Old 3.Permanent。 Young保存刚实例化的对象。当该区被填满时，GC会将对象移到Old区。Permanent区则负责保存反射对象，本文不讨论该区。 JVM有2个GC线程： 第一个线程负责回收Heap的Young区；第二个线程在Heap不足时，遍历Heap，将Young 区升级为Older区，Older区的大小等于-Xmx减去-Xmn，不能将-Xms的值设的过大，因为第二个线程被迫运行会降低JVM的性能。","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"},{"name":"TOMCAT","slug":"TOMCAT","permalink":"https://banghuaji.github.io/tags/TOMCAT/"}]},{"title":"DOCKER中JAVA应用自动设置堆内存","slug":"docker/DOCKER中JAVA应用自动设置堆内存","date":"2017-12-24T07:09:35.145Z","updated":"2017-12-24T07:09:26.000Z","comments":true,"path":"2017/12/24/docker/DOCKER中JAVA应用自动设置堆内存/","link":"","permalink":"https://banghuaji.github.io/2017/12/24/docker/DOCKER中JAVA应用自动设置堆内存/","excerpt":"","text":"JAVA应用中我们为了让应用更好的工作，我们经常的要设置堆内存等的操作。 但是我们经常的会指定DOCKER的最大内存值，怎样让我们设置了DOCKER的内存值来指定TOMCAT里面需要的值那，下面是从网上找到的解决的方案： GITHUB的地址：https://github.com/denverdino/docker-tomcat-autoheap 12345678910111213#!/bin/bashlimit_in_bytes=$(cat /sys/fs/cgroup/memory/memory.limit_in_bytes)# If not default limit_in_bytes in cgroupif [ &quot;$limit_in_bytes&quot; -ne &quot;9223372036854771712&quot; ]then limit_in_megabytes=$(expr $limit_in_bytes \\/ 1048576) heap_size=$(expr $limit_in_megabytes - $RESERVED_MEGABYTES) export JAVA_OPTS=&quot;-Xmx$&#123;heap_size&#125;m $JAVA_OPTS&quot; echo JAVA_OPTS=$JAVA_OPTSfiexec catalina.sh run 现在我们启动一个tomcat运行在512兆的容器中 1docker run -d --name test -m 512m registry.aliyuncs.com/denverdino/tomcat:8-autoheap 通过下列命令，从日志中我们可以检测到相应的JVM参数已经被设置成 256MB (512-256) 12345docker logs test...02-Apr-2016 14:18:09.870 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Xmx256m...","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"}]},{"title":"Linux如何查找大文件或目录总结","slug":"linux/查找大文件或目录总结","date":"2017-12-09T09:32:03.848Z","updated":"2017-12-09T09:30:35.000Z","comments":true,"path":"2017/12/09/linux/查找大文件或目录总结/","link":"","permalink":"https://banghuaji.github.io/2017/12/09/linux/查找大文件或目录总结/","excerpt":"","text":"文件排序123456789101112131415161. df -lh2. du -s /usr/* | sort -rn这是按字节排序3. du -sh /usr/* | sort -rn这是按兆（M）来排序4.选出排在前面的10个du -s /usr/* | sort -rn | head5.选出排在后面的10个du -s /usr/* | sort -rn | taildu -h –-max-depth=0 userdu -sh –-max-depth=2 | more 如何查找大文件我要搜索当前目录下，超过800M大小的文件12345678910[root@getlnx01 u03]# pwd/u03[root@getlnx01 u03]# find . -type f -size +800M./flash_recovery_area/backup/backupsets/ora_df873519197_s46815_s1./flash_recovery_area/backup/backupsets/ora_df873523646_s46822_s1./flash_recovery_area/backup/backupsets/ora_df873521714_s46818_s1./flash_recovery_area/backup/backupsets/ora_df873522876_s46820_s1./flash_recovery_area/backup/backupsets/ora_df873517396_s46813_s1./flash_recovery_area/backup/backupsets/ora_df873523321_s46821_s1./flash_recovery_area/backup/backupsets/ora_df873515765_s46811_s1 我们仅仅能看到超过800M大小的文件的文件名称，但是对文件的信息（例如，文件大小、文件属性）1234567[root@getlnx01 u03]# find . -type f -size +800M -print0 | xargs -0 ls -l-rw-r----- 1 oracle oinstall 2782846976 Mar 6 11:51 ./flash_recovery_area/backup/backupsets/ora_df873513413_s46809_s1-rw-r----- 1 oracle oinstall 1878433792 Mar 6 11:53 ./flash_recovery_area/backup/backupsets/ora_df873514789_s46810_s1-rw-r----- 1 oracle oinstall 1378492416 Mar 6 11:54 ./flash_recovery_area/backup/backupsets/ora_df873515765_s46811_s1-rw-r----- 1 oracle oinstall 1641381888 Mar 6 11:56 ./flash_recovery_area/backup/backupsets/ora_df873516500_s46812_s1-rw-r----- 1 oracle oinstall 1564065792 Mar 6 11:58 ./flash_recovery_area/backup/backupsets/ora_df873517396_s46813_s1-rw-r----- 1 oracle oinstall 1663492096 Mar 6 12:00 当我们只需要查找超过800M大小文件，并显示查找出来文件的具体大小，可以使用下面命令12345678[root@getlnx01 u03]# find . -type f -size +800M -print0 | xargs -0 du -h1.3G ./flash_recovery_area/backup/backupsets/ora_df873519197_s46815_s11.1G ./flash_recovery_area/backup/backupsets/ora_df873523646_s46822_s11.2G ./flash_recovery_area/backup/backupsets/ora_df873521714_s46818_s11.2G ./flash_recovery_area/backup/backupsets/ora_df873522876_s46820_s11.5G ./flash_recovery_area/backup/backupsets/ora_df873517396_s46813_s11.1G ./flash_recovery_area/backup/backupsets/ora_df873523321_s46821_s11.3G ./flash_recovery_area/backup/backupsets/ora_df873515765_s46811_s1 如果你还需要对查找结果按照文件大小做一个排序，那么可以使用下面命令123456789root@getlnx01 u03]# find . -type f -size +800M -print0 | xargs -0 du -h | sort -nr1004M ./flash_recovery_area/backup/backupsets/ora_df873524162_s46823_s18.1G ./oradata/epps/undotbs02.dbf8.1G ./oradata/epps/undotbs01.dbf4.1G ./oradata/epps/invsubmat_d08.dbf4.1G ./oradata/epps/gmtinv_x02.dbf4.1G ./oradata/epps/gmtinv_x01.dbf4.1G ./oradata/epps/gmtinv_d07.dbf4.0G ./oradata/epps/gmtinv_d08.dbf 如何查找Linux下的大目录譬如有时候磁盘空间告警了，而你平时又疏于管理、监控文件的增长，那么我需要快速的了解哪些目录变得比较大，那么此时我们可以借助du命令来帮我们解决这个问题。12345[root@getlnx01 u03]# du -h --max-depth=116K ./lost+found33G ./flash_recovery_area37G ./oradata70G . 如果你想知道flash_recovery_area目录下面有哪些大文件夹，那么可以将参数max-depth=2 ，如果你想对搜索出来的结果进行排序，那么可以借助于sort命令。如下所示12345678910111213141516[root@getlnx01 u03]# du -h --max-depth=2 | sort -n3.5G ./flash_recovery_area/EPPS16K ./lost+found29G ./flash_recovery_area/backup33G ./flash_recovery_area37G ./oradata37G ./oradata/epps70G .[root@getlnx01 u03]# du -hm --max-depth=2 | sort -n1 ./lost+found3527 ./flash_recovery_area/EPPS29544 ./flash_recovery_area/backup33070 ./flash_recovery_area37705 ./oradata37705 ./oradata/epps70775 . 有时候搜索出来的结果太多了（譬如，我从根目录开始搜索），一直在刷屏，如果我只想查出最大的15个文件夹，怎么办呢？此时就要借助head命令来显示了1[root@getlnx01 u03]# du -hm --max-depth=2 | sort -n |head -15","categories":[],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://banghuaji.github.io/tags/LINUX/"}]},{"title":"Dockerfile--WORKDIR","slug":"docker/Dockerfile--WORKDIR","date":"2017-11-29T12:59:02.616Z","updated":"2017-11-26T13:29:17.000Z","comments":true,"path":"2017/11/29/docker/Dockerfile--WORKDIR/","link":"","permalink":"https://banghuaji.github.io/2017/11/29/docker/Dockerfile--WORKDIR/","excerpt":"","text":"Dockerfile中的WORKDIR指令用于指定容器的一个目录， 容器启动时执行的命令会在该目录下执行。 相当于设置容器的工作目录了。我们来看一个dockerfile文件 1234567#testFROM ubuntuMAINTAINER helloRUN mkdir /mydirRUN echo hello world &gt; /mydir/test.txtWORKDIR /mydirCMD [&quot;more&quot; ,&quot;test.txt&quot;] 假设根据该dockerfile构建的镜像名为 myimage 1231、运行 docker run myimage 输出 hello world2、运行 docker run myimage more test.txt 和上面输出一致 可以看出，more的参数是 test.txt，但没有指定路径，却能成功，说明当前路径就是上面WORKDIR指令设置的。 如果我们在上面的dockerfile中把WORKDIR指令去掉，创建的容器运行会报文件不存在错误。 3、可以在 docker run命令中用 -w参数覆盖掉WORKDIR指令的设置，如： 执行 docker run -w / myimage 上面的-w参数将容器的工作目录设置成了根目录，而根目录下没有test.txt文件。 所以结果显示：test.txt: No such file or directory","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"}]},{"title":"Dockerfile-ADD&CPOY","slug":"docker/Dockerfile-ADD2CPOY","date":"2017-11-29T12:59:02.472Z","updated":"2017-11-26T13:29:52.000Z","comments":true,"path":"2017/11/29/docker/Dockerfile-ADD2CPOY/","link":"","permalink":"https://banghuaji.github.io/2017/11/29/docker/Dockerfile-ADD2CPOY/","excerpt":"","text":"一、ADD指令ADD指令的功能是将主机构建环境（上下文）目录中的文件和目录、以及一个URL标记的文件 拷贝到镜像中。 其格式是：1ADD 源路径 目标路径 如： #test 12345678FROM ubuntuMAINTAINER helloADD test1.txt test1.txtADD test1.txt test1.txt.bakADD test1.txt /mydir/ADD data1 data1ADD data2 data2ADD zip.tar /myzip 有如下注意事项： 1、如果源路径是个文件，且目标路径是以 / 结尾， 则docker会把目标路径当作一个目录，会把源文件拷贝到该目录下。 如果目标路径不存在，则会自动创建目标路径。 2、如果源路径是个文件，且目标路径是不是以 / 结尾，则docker会把目标路径当作一个文件。 如果目标路径不存在，会以目标路径为名创建一个文件，内容同源文件； 如果目标文件是个存在的文件，会用源文件覆盖它，当然只是内容覆盖，文件名还是目标文件名。 如果目标文件实际是个存在的目录，则会源文件拷贝到该目录下。 注意，这种情况下，最好显示的以 / 结尾，以避免混淆。 3、如果源路径是个目录，且目标路径不存在，则docker会自动以目标路径创建一个目录，把源路径目录下的文件拷贝进来。 如果目标路径是个已经存在的目录，则docker会把源路径目录下的文件拷贝到该目录下。 4、如果源文件是个归档文件（压缩文件），则docker会自动帮解压。 COPY指令COPY指令和ADD指令功能和使用方式类似。只是COPY指令不会做自动解压工作。","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"}]},{"title":"Dockerfile-USER 介绍","slug":"docker/Dockerfile-USER","date":"2017-11-29T12:59:02.243Z","updated":"2017-11-26T13:29:03.000Z","comments":true,"path":"2017/11/29/docker/Dockerfile-USER/","link":"","permalink":"https://banghuaji.github.io/2017/11/29/docker/Dockerfile-USER/","excerpt":"","text":"USER指令用于指定容器执行程序的用户身份，默认是 root用户。 在docker run 中可以通过 -u 选项来覆盖USER指令的设置。 举例：1docker run -i -t -u mysql newmysqldb /bin/bash 显示的shell提示符是： 1mysql@57cd57edba38:/$ 注意：docker容器中的root用户密码是随机分配的。","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"}]},{"title":"Dockerfile-VOLUME 介绍","slug":"docker/Dockerfile-VOLUME","date":"2017-11-29T12:59:01.161Z","updated":"2017-11-26T13:28:35.000Z","comments":true,"path":"2017/11/29/docker/Dockerfile-VOLUME/","link":"","permalink":"https://banghuaji.github.io/2017/11/29/docker/Dockerfile-VOLUME/","excerpt":"","text":"在介绍VOLUME指令之前，我们来看下如下场景需求： 1）容器是基于镜像创建的，最后的容器文件系统包括镜像的只读层+可写层，容器中的进程操作的数据持久化都是保存在容器的可写层上。一旦容器删除后，这些数据就没了，除非我们人工备份下来（或者基于容器创建新的镜像）。能否可以让容器进程持久化的数据保存在主机上呢？这样即使容器删除了，数据还在。 2）当我们在开发一个web应用时，开发环境是在主机本地，但运行测试环境是放在docker容器上。 这样的话，我在主机上修改文件（如html，js等）后，需要再同步到容器中。这显然比较麻烦。 3）多个容器运行一组相关联的服务，如果他们要共享一些数据怎么办？ 对于这些问题，我们当然能想到各种解决方案。而docker本身提供了一种机制，可以将主机上的某个目录与容器的某个目录（称为挂载点、或者叫卷）关联起来，容器上的挂载点下的内容就是主机的这个目录下的内容，这类似linux系统下mount的机制。 这样的话，我们修改主机上该目录的内容时，不需要同步容器，对容器来说是立即生效的。 挂载点可以让多个容器共享。 下面我们来介绍具体的机制。 一、通过docker run命令1、运行命令：1docker run --name test -it -v /home/xqh/myimage:/data ubuntu /bin/bash 其中的 -v 标记 在容器中设置了一个挂载点 /data（就是容器中的一个目录），并将主机上的 /home/xqh/myimage 目录中的内容关联到 /data下。 这样在容器中对/data目录下的操作，还是在主机上对/home/xqh/myimage的操作，都是完全实时同步的，因为这两个目录实际都是指向主机目录。 2、运行命令：docker run –name test1 -it -v /data ubuntu /bin/bash 上面-v的标记只设置了容器的挂载点，并没有指定关联的主机目录。这时docker会自动绑定主机上的一个目录。通过docker inspect 命令可以查看到。 12345678910111213141516xqh@ubuntu:~/myimage$ docker inspect test1[&#123; &quot;Id&quot;: &quot;1fd6c2c4bc545163d8c5c5b02d60052ea41900a781a82c20a8f02059cb82c30c&quot;,............................. &quot;Mounts&quot;: [ &#123; &quot;Name&quot;: &quot;0ab0aaf0d6ef391cb68b72bd8c43216a8f8ae9205f0ae941ef16ebe32dc9fc01&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/0ab0aaf0d6ef391cb68b72bd8c43216a8f8ae9205f0ae941ef16ebe32dc9fc01/_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true &#125; ],........................... 复制代码上面 Mounts下的每条信息记录了容器上一个挂载点的信息，”Destination” 值是容器的挂载点，”Source”值是对应的主机目录。 可以看出这种方式对应的主机目录是自动创建的，其目的不是让在主机上修改，而是让多个容器共享。 二、通过dockerfile创建挂载点上面介绍的通过docker run命令的-v标识创建的挂载点只能对创建的容器有效。 通过dockerfile的 VOLUME 指令可以在镜像中创建挂载点，这样只要通过该镜像创建的容器都有了挂载点。 还有一个区别是，通过 VOLUME 指令创建的挂载点，无法指定主机上对应的目录，是自动生成的。 1234#testFROM ubuntuMAINTAINER hello1VOLUME [&quot;/data1&quot;,&quot;/data2&quot;] 上面的dockfile文件通过VOLUME指令指定了两个挂载点 /data1 和 /data2. 我们通过docker inspect 查看通过该dockerfile创建的镜像生成的容器，可以看到如下信息 复制代码 123456789101112131415161718&quot;Mounts&quot;: [ &#123; &quot;Name&quot;: &quot;d411f6b8f17f4418629d4e5a1ab69679dee369b39e13bb68bed77aa4a0d12d21&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/d411f6b8f17f4418629d4e5a1ab69679dee369b39e13bb68bed77aa4a0d12d21/_data&quot;, &quot;Destination&quot;: &quot;/data1&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true &#125;, &#123; &quot;Name&quot;: &quot;6d3badcf47c4ac5955deda6f6ae56f4aaf1037a871275f46220c14ebd762fc36&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/6d3badcf47c4ac5955deda6f6ae56f4aaf1037a871275f46220c14ebd762fc36/_data&quot;, &quot;Destination&quot;: &quot;/data2&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true &#125; ], 复制代码可以看到两个挂载点的信息。 三、容器共享卷（挂载点）docker run –name test1 -it myimage /bin/bash 上面命令中的 myimage是用前面的dockerfile文件构建的镜像。 这样容器test1就有了 /data1 和 /data2两个挂载点。 下面我们创建另一个容器可以和test1共享 /data1 和 /data2卷 ，这是在 docker run中使用 –volumes-from标记，如： 可以是来源不同镜像，如： docker run –name test2 -it –volumes-from test1 ubuntu /bin/bash 也可以是同一镜像，如： docker run –name test3 -it –volumes-from test1 myimage /bin/bash 上面的三个容器 test1 , test2 , test3 均有 /data1 和 /data2 两个目录，且目录中内容是共享的，任何一个容器修改了内容，别的容器都能获取到。 四、最佳实践：数据容器如果多个容器需要共享数据（如持久化数据库、配置文件或者数据文件等），可以考虑创建一个特定的数据容器，该容器有1个或多个卷。 其它容器通过–volumes-from 来共享这个数据容器的卷。 因为容器的卷本质上对应主机上的目录，所以这个数据容器也不需要启动。 1如： docker run --name dbdata myimage echo &quot;data container&quot; 说明：有个卷，容器之间的数据共享比较方便，但也有很多问题需要解决，如权限控制、数据的备份、卷的删除等。这些内容后续文章介绍。","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"}]},{"title":"Dockerfile-CMD","slug":"docker/Dockerfile-CMD","date":"2017-11-29T12:59:00.585Z","updated":"2017-11-26T13:29:30.000Z","comments":true,"path":"2017/11/29/docker/Dockerfile-CMD/","link":"","permalink":"https://banghuaji.github.io/2017/11/29/docker/Dockerfile-CMD/","excerpt":"","text":"CMD我们知道，通过docker run 创建并启动一个容器时，命令的最后可以指定容器启动后在容器内立即要执行的指令，如： 123docker run -i -t ubunu /bin/bash //表示容器启动时立即在容器内打开一个shell终端docker run ubuntu /bin/ps //表示容器启动后立即运行 /bin/ps命令，显示容器的当前进程 。 除了这种方式外，我们可以在dockerfile文件中通过CMD指令指定容器启动时要执行的命令。如： 复制代码 12345678#testFROM ubuntuMAINTAINER xxxRUN echo hello1 &gt; test1.txtRUN echo hello2 &gt; /test2.txtEXPOSE 80EXPOSE 81CMD [&quot;/bin/bash&quot;] 复制代码上面dockerfile文件中最后一行CMD指令的参数是指定容器启动时要执行的命令，这里是bin/bash命令。 1、用docker run命令创建并启动容器（myimage 是用前面dockerfile创建的镜像的名称）： 1docker run -i -t myimage 上面命令是创建并启动容器，打开一个交互式shell。 而以前的写法是 1docker run -i -t myimage /bin/bash 这样就省去了在docker run中写命令了。 2、即使dockerfile中有CMD指令，我们仍然可以在docker run命令中带上容器启动时执行的命令，这会覆盖dockerfile中的CMD指令指定的命令。如： 1docker run -i -t myimage /bin/ps 上面命令，因为/bin/ps覆盖了CMD指令，启动容器时会打印容器内的当前进程，但容器会立即停止，因为/bin/bash被覆盖了，无法打开交互式shell界面。 3、需要注意的是，dockerfile中可以有多条cmd命令，但只是最后一条有效。 4、CMD命令的参数格式，一般写成 字符串数组的方式，如上面的例子。如： 1CMD [&quot;echo&quot;,&quot;hello world&quot;] 虽然也可写成CMD echo hello word 方式，但这样docker会在指定的命令前加 /bin/sh -c 执行，有时有可能会出问题。 所以推荐采用数据结构的方式来存放命令。 ENTRYPOINT","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"}]},{"title":"Dockerfile-ENTRYPOINT","slug":"docker/Dockerfile-ENTRYPOINT","date":"2017-11-29T12:58:56.686Z","updated":"2017-11-26T13:29:43.000Z","comments":true,"path":"2017/11/29/docker/Dockerfile-ENTRYPOINT/","link":"","permalink":"https://banghuaji.github.io/2017/11/29/docker/Dockerfile-ENTRYPOINT/","excerpt":"","text":"本文介绍Dockerfile的 ENTRYPOINT指令的含义。 先回顾下CMD指令的含义，CMD指令可以指定容器启动时要执行的命令，但它可以被docker run命令的参数覆盖掉。 ENTRYPOINT 指令和CMD类似，它也可用户指定容器启动时要执行的命令，但如果dockerfile中也有CMD指令，CMD中的参数会被附加到ENTRYPOINT 指令的后面。 如果这时docker run命令带了参数，这个参数会覆盖掉CMD指令的参数，并也会附加到ENTRYPOINT 指令的后面。 这样当容器启动后，会执行ENTRYPOINT 指令的参数部分。 可以看出，相对来说ENTRYPOINT指令优先级更高。 我们来看个例子，下面是Dockerfile的内容 12345678#testFROM ubuntuMAINTAINER helloRUN echo hello1 &gt; test1.txtRUN echo hello2 &gt; /test2.txtEXPOSE 80ENTRYPOINT [&quot;echo&quot;]CMD [&quot;defaultvalue&quot;] 假设通过该Dockerfile构建的镜像名为 myimage。 1、当运行 docker run myimage 输出的内容是 defaultvalue，可以看出CMD指令的参数得确是被添加到ENTRYPOINT指令的后面，然后被执行。 2、当运行docker run myimage hello world 输出的内容是 hello world ，可以看出docker run命令的参数得确是被添加到ENTRYPOINT指令的后面，然后被执行，这时CMD指令被覆盖了。 3、另外我们可以在docker run命令中通过 –entrypoint 覆盖dockerfile文件中的ENTRYPOINT设置，如： 1docker run --entrypoint=&quot;echo&quot; myimage good 结果输出good 注意，不管是哪种方式，创建容器后，通过 dokcer ps查看容器信息时，COMMOND列会显示最终生效的启动命令。","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"}]},{"title":"Groovy脚本基础全攻略","slug":"language/groovy/Groovy脚本基础全攻略","date":"2017-11-03T13:10:38.090Z","updated":"2017-11-03T04:42:46.000Z","comments":true,"path":"2017/11/03/language/groovy/Groovy脚本基础全攻略/","link":"","permalink":"https://banghuaji.github.io/2017/11/03/language/groovy/Groovy脚本基础全攻略/","excerpt":"","text":"背景Groovy脚本基于Java且拓展了Java，所以从某种程度来说掌握Java是学习Groovy的前提，故本文适用于不熟悉Groovy却想快速得到Groovy核心基础干货的Java开发者（注意是Java），因为我的目的不是深入学习Groovy语言，所以本文基本都是靠代码来解释，这样最直观，同时也够干货基础入门Groovy的特点和结构。 Groovy是一种动态语言，它和Java类似（算是Java的升级版，但是又具备脚本语言的特点），都在Java虚拟机中运行。当运行Groovy脚本时它会先被编译成Java类字节码，然后通过JVM虚拟机执行这个Java字节码类。 快速安装指南：我们在写Groovy代码时可以直接使用自己喜欢的文本编辑器编辑OK以后以.groovy后缀保存，然后在终端执行如下命令即可运行： 1$ groovy ./TestFile.groovy 再或者我们还可以使用Intellij IDEA等工具安装groovy插件进行groovy开发，这里不再一一叙述了（配置环境点我），直接给出一个读取指定文件内容打印的例子，如下： 语法基础注释Groovy的单行注释、多行注释、文档注释基本都和Java一样，没啥特殊的，不再细说。只有一种特殊的单行注释需要留意一下即可。如下：12#!/usr/bin/env groovyprintln &quot;Hello from the shebang line&quot; 这种注释通常是用来给UNIX系统声明允许脚本运行的类型的，一般都是固定写法，没啥讲究的。 关键字Groovy有如下一些关键字，我们些代码命名时要注意： 12as、assert、break、case、catch、class、const、continue、def、default、do、else、enum、extends、false、finally、for、goto、if、implements、import、in、instanceof、interface、new、null、package、return、super、switch、this、throw、throws、trait、true、try、while 这玩意和其他语言一样，没啥特殊的，自行脑补。 标识符对于Groovy的标示符和Java还是有些共同点和区别的，特别是引用标示符的区别，具体可以往下看。 普通标识符普通标识符定义和C语言类似，只能以字母、美元符、下划线开始，不能以数字开头。如下例子： 12345678//正确def namedef $namedef name_typedef foo.assert//错误def 5typedef a+b 引用标识符引用标识符出现在点后的表达式中，我们可以如下一样使用： 12345678def map = [:]//引用标示符中出现空格也是对的map.&quot;an identifier with a space and double quotes&quot; = &quot;ALLOWED&quot;//引用标示符中出现横线也是对的map.&apos;with-dash-signs-and-single-quotes&apos; = &quot;ALLOWED&quot;assert map.&quot;an identifier with a space and double quotes&quot; == &quot;ALLOWED&quot;assert map.&apos;with-dash-signs-and-single-quotes&apos; == &quot;ALLOWED&quot; Groovy的所有字符串都可以当作引用标示符定义，如下： 12345678910111213//如下类型字符串作为引用标识符都是对的map.&apos;single quote&apos;map.&quot;double quote&quot;map.&apos;&apos;&apos;triple single quote&apos;&apos;&apos;map.&quot;&quot;&quot;triple double quote&quot;&quot;&quot;map./slashy string/map.$/dollar slashy string/$//稍微特殊的GString，也是对的def firstname = &quot;Homer&quot;map.&quot;Simson-$&#123;firstname&#125;&quot; = &quot;Homer Simson&quot;assert map.&apos;Simson-Homer&apos; == &quot;Homer Simson 字符及字符串Groovy有java.lang.String和groovy.lang.GString两中字符串对象类型，具体如下细说。 单引号字符串单引号字符串是java.lang.String类型的，不支持站位符插值操作，譬如： 12345def name = &apos;Test Groovy!&apos;def body = &apos;Test $name&apos;assert name == &apos;Test Groovy!&apos;assert body == &apos;Test $name&apos; //不会替换$name站位符 123Groovy的字符串可以通过”+“直接拼接，譬如：assert &apos;ab&apos; == &apos;a&apos; + &apos;b&apos; 其中涉及转义字符规则同Java，只用特殊注意”’“的转义即可。 三重单引号字符串三重单引号字符串是java.lang.String类型的，不支持站位符插值操作，可以标示多行字符串，譬如： 123def aMultilineString = &apos;&apos;&apos;line oneline twoline three&apos;&apos;&apos; 三重单引号字符串允许字符串的内容在多行出现，新的行被转换为“\\n”，其他所有的空白字符都被完整的按照文本原样保留；字符开头添加“/”表示字符内容不转义反斜杠“\\”，只有在反斜杠接下来是一个字符u的时候才需要进行转义，因为\\u表示一个unicode转义。如下： 1234567def strippedFirstNewline = &apos;&apos;&apos;\\line oneline twoline three&apos;&apos;&apos;assert !strippedFirstNewline.startsWith(&apos;\\n&apos;) 双引号字符串双引号字符串支持站位插值操作，如果双引号字符串中不包含站位符则是java.lang.String类型的，如果双引号字符串中包含站位符则是groovy.lang.GString类型的。 对于插值占位符我们可以用${}或者$来标示，${}用于一般替代字串或者表达式，$主要用于A.B的形式中，具体如下例子： 123456789def name = &apos;Guillaume&apos; // a plain stringdef greeting = &quot;Hello $&#123;name&#125;&quot;assert greeting.toString() == &apos;Hello Guillaume&apos;def sum = &quot;The sum of 2 and 3 equals $&#123;2 + 3&#125;&quot;assert sum.toString() == &apos;The sum of 2 and 3 equals 5&apos;def person = [name: &apos;Guillaume&apos;, age: 36]assert &quot;$person.name is $person.age years old&quot; == &apos;Guillaume is 36 years old&apos; 特别注意，$只对A.B等有效，如果表达式包含括号（像方法调用）、大括号、闭包等符号则是无效的。譬如： 1234def number = 3.14shouldFail(MissingPropertyException) &#123; println &quot;$number.toString()&quot;&#125; //该代码运行抛出groovy.lang.MissingPropertyException异常，因为Groovy认为去寻找number的名为toString的属性，所以异常 注意，在表达式中访问属性前必须保证属性已经定义好(值为空也可以)，如果使用了未定义的属性会抛出groovy.lang.MissingPropertyException异常。 GString还支持延迟运算，譬如在GString中使用闭包，闭包在调用GString的toString()方法时被延迟执行；闭包中可以有0或1个参数，若指定一个参数，则参数会被传入一个Writer对象，我们可以利用这个Writer对象来写入字符，若没有参数，闭包返回值的toString()方法被调用。譬如： 123456//无参数闭包def sParameterLessClosure = &quot;1 + 2 == $&#123;-&gt; 3&#125;&quot; assert sParameterLessClosure == &apos;1 + 2 == 3&apos;//一个参数闭包def sOneParamClosure = &quot;1 + 2 == $&#123; w -&gt; w &lt;&lt; 3&#125;&quot; assert sOneParamClosure == &apos;1 + 2 == 3&apos; 上面了解了GString的推迟运算特性，下面我们再来看一个牛逼的特性，如下： 12345678910def number = 1 def eagerGString = &quot;value == $&#123;number&#125;&quot;def lazyGString = &quot;value == $&#123; -&gt; number &#125;&quot;assert eagerGString == &quot;value == 1&quot; assert lazyGString == &quot;value == 1&quot; number = 2 assert eagerGString == &quot;value == 1&quot; assert lazyGString == &quot;value == 2&quot; 可以看见，eagerGString是普通的双引号插值站位替换，lazyGString是双引号闭包插值替换，我们可以发现在number变为2以后他们的运算结果就有了差异。可以明显推理到结论，一个普通插值表达式值替换实际是在GString创建的时刻，一个包含闭包的表达式由于延迟运算调运toString()方法，所以会产生一个新的字符串值。 当然了，GString和String即使字符串一样他们的HashCode也不会一样，譬如： 1assert &quot;one: $&#123;1&#125;&quot;.hashCode() != &quot;one: 1&quot;.hashCode() 由于相同字符串的String与GString的HashCode不同，所以我们一定要避免使用GString作为MAP的key，譬如： 1234def key = &quot;a&quot;def m = [&quot;$&#123;key&#125;&quot;: &quot;letter $&#123;key&#125;&quot;] assert m[&quot;a&quot;] == null //由于key的HashCode不同，所以取不到 其中涉及转义字符规则同Java，只用特殊注意””“的转义即可。 多重双引号字符串多重双引号字符串也支持站位插值操作，我们要特别注意在多重双引号字符串中的单引号和双引号转换问题。譬如： 123456789101112def name = &apos;Groovy&apos;def template = &quot;&quot;&quot; Dear Mr $&#123;name&#125;, You&apos;re the winner of the lottery! Yours sincerly, Dave&quot;&quot;&quot;assert template.toString().contains(&apos;Groovy&apos;) 斜线字符串斜线字符串其实和双引号字符串很类似，通常用在正则表达式中，下面我们看几个例子，如下： 1234567891011121314151617//普通使用def fooPattern = /.*foo.*/assert fooPattern == &apos;.*foo.*&apos;//含转义字符使用def escapeSlash = /The character \\/ is a forward slash/assert escapeSlash == &apos;The character / is a forward slash&apos;//多行支持def multilineSlashy = /one two three/assert multilineSlashy.contains(&apos;\\n&apos;)//含站位符使用支持def color = &apos;blue&apos;def interpolatedSlashy = /a $&#123;color&#125; car/assert interpolatedSlashy == &apos;a blue car&apos; 特别注意，一个空的斜线字符串会被Groovy解析器解析为一注释。 字符Characters不像Java，Groovy没有明确的Characters。但是我们可以有如下三种不同的方式来将字符串作为字符处理，譬如： 12345678char c1 = &apos;A&apos; assert c1 instanceof Characterdef c2 = &apos;B&apos; as char assert c2 instanceof Characterdef c3 = (char)&apos;C&apos; assert c3 instanceof Character 数字NumbersGroovy支持各种类型的整型和数值类型，通常支持Java支持的那些，下面我们仔细来说说。 整型Groovy像Java一样支持如下一些整型，byte、char、short、int、long、java.lang.BigInteger。我们在使用中可以像下面例子一样： 12345678910111213141516171819// primitive typesbyte b = 1char c = 2short s = 3int i = 4long l = 5// infinite precisionBigInteger bi = 6int xInt = 077assert xInt == 63int xInt = 0x77assert xInt == 119int xInt = 0b10101111assert xInt == 175 浮点型Groovy像Java一样支持如下一些浮点型，float、double、java.lang.BigDecimal。我们在使用中可以像下面例子一样： 123456789101112// primitive typesfloat f = 1.234double d = 2.345// infinite precisionBigDecimal bd = 3.456assert 1e3 == 1_000.0assert 2E4 == 20_000.0assert 3e+1 == 30.0assert 4E-2 == 0.04 Booleans类型Boolean类型没啥解释的，和其他语言一样，就两个值，如下： 123456def myBooleanVariable = trueboolean untypedBooleanVar = falsebooleanField = true123 比较简单，没啥特例，自行脑补。 Lists类型Groovy同样支持java.util.List类型，在Groovy中同样允许向列表中增加或者删除对象，允许在运行时改变列表的大小，保存在列表中的对象不受类型的限制；此外还可以通过超出列表范围的数来索引列表。如下例子： 123456789101112131415161718192021222324252627282930313233343536373839404142//使用动态Listdef numbers = [1, 2, 3] assert numbers instanceof List assert numbers.size() == 3//List中存储任意类型def heterogeneous = [1, &quot;a&quot;, true]//判断List默认类型def arrayList = [1, 2, 3]assert arrayList instanceof java.util.ArrayList//使用as强转类型def linkedList = [2, 3, 4] as LinkedList assert linkedList instanceof java.util.LinkedList//定义指定类型ListLinkedList otherLinked = [3, 4, 5] assert otherLinked instanceof java.util.LinkedList//定义List使用def letters = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;]//判断item值assert letters[0] == &apos;a&apos; assert letters[1] == &apos;b&apos;//负数下标则从右向左indexassert letters[-1] == &apos;d&apos; assert letters[-2] == &apos;c&apos;//指定item赋值判断letters[2] = &apos;C&apos; assert letters[2] == &apos;C&apos;//给List追加itemletters &lt;&lt; &apos;e&apos; assert letters[ 4] == &apos;e&apos;assert letters[-1] == &apos;e&apos;//获取一段List子集assert letters[1, 3] == [&apos;b&apos;, &apos;d&apos;] assert letters[2..4] == [&apos;C&apos;, &apos;d&apos;, &apos;e&apos;] //多维List支持def multi = [[0, 1], [2, 3]] assert multi[1][0] == 2 Arrays类型Groovy中数组和Java类似，具体如下： 123456789101112131415161718192021222324//定义初始化String数组String[] arrStr = [&apos;Ananas&apos;, &apos;Banana&apos;, &apos;Kiwi&apos;] assert arrStr instanceof String[] assert !(arrStr instanceof List)//使用def定义初始化int数组def numArr = [1, 2, 3] as int[] assert numArr instanceof int[] assert numArr.size() == 3//声明定义多维数组指明宽度def matrix3 = new Integer[3][3] assert matrix3.size() == 3//声明多维数组不指定宽度Integer[][] matrix2 matrix2 = [[1, 2], [3, 4]]assert matrix2 instanceof Integer[][]//数组的元素使用及赋值操作String[] names = [&apos;Cédric&apos;, &apos;Guillaume&apos;, &apos;Jochen&apos;, &apos;Paul&apos;]assert names[0] == &apos;Cédric&apos; names[2] = &apos;Blackdrag&apos; assert names[2] == &apos;Blackdrag&apos; Maps类型Map是“键-值”对的集合，在Groovy中键key不一定是String，可以是任何对象(实际上Groovy中的Map就是java.util.Linke dHashMap)。如下： 123456789101112131415161718//定义一个Mapdef colors = [red: &apos;#FF0000&apos;, green: &apos;#00FF00&apos;, blue: &apos;#0000FF&apos;] //获取一些指定key的value进行判断操作assert colors[&apos;red&apos;] == &apos;#FF0000&apos; assert colors.green == &apos;#00FF00&apos;//给指定key的对赋值value操作与判断 colors[&apos;pink&apos;] = &apos;#FF00FF&apos; colors.yellow = &apos;#FFFF00&apos; assert colors.pink == &apos;#FF00FF&apos;assert colors[&apos;yellow&apos;] == &apos;#FFFF00&apos;//判断Map的类型assert colors instanceof java.util.LinkedHashMap//访问Map中不存在的key为nullassert colors.unknown == null//定义key类型为数字的Mapdef numbers = [1: &apos;one&apos;, 2: &apos;two&apos;]assert numbers[1] == &apos;one&apos; 123456789101112对于Map需要特别注意一种情况，如下：//把一个定义的变量作为Map的key，访问Map的该key是失败的def key = &apos;name&apos;def person = [key: &apos;Guillaume&apos;] assert !person.containsKey(&apos;name&apos;) assert person.containsKey(&apos;key&apos;) //把一个定义的变量作为Map的key的正确写法---添加括弧，访问Map的该key是成功的person = [(key): &apos;Guillaume&apos;] assert person.containsKey(&apos;name&apos;) assert !person.containsKey(&apos;key&apos;) 运算符关于Groovy的运算符介绍类似于上面一样，我们重点突出与Java的不同点，相同点自行脑补。 Groovy支持**次方运算符，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354assert 2 ** 3 == 8def f = 3f **= 2assert f == 9Groovy非运算符如下：assert (!true) == false assert (!&apos;foo&apos;) == false assert (!&apos;&apos;) == true Groovy支持?.安全占位符，这个运算符主要用于避免空指针异常，譬如：def person = Person.find &#123; it.id == 123 &#125; def name = person?.name assert name == null Groovy支持.@直接域访问操作符，因为Groovy自动支持属性getter方法，但有时候我们有一个自己写的特殊getter方法，当不想调用这个特殊的getter方法则可以用直接域访问操作符。如下：class User &#123; public final String name User(String name) &#123; this.name = name&#125; String getName() &#123; &quot;Name: $name&quot; &#125; &#125;def user = new User(&apos;Bob&apos;)assert user.name == &apos;Name: Bob&apos;assert user.@name == &apos;Bob&apos; 1Groovy支持.&amp;方法指针操作符，因为闭包可以被作为一个方法的参数，如果想让一个方法作为另一个方法的参数则可以将一个方法当成一个闭包作为另一个方法的参数。如下： def list = [&apos;a&apos;,&apos;b&apos;,&apos;c&apos;] //常规写法 list.each&#123; println it &#125; String printName(name)&#123; println name &#125; //方法指针操作符写法 list.each(this.&amp;printName) Groovy支持将?:三目运算符简化为二目，如下：123456789101112displayName = user.name ? user.name : &apos;Anonymous&apos; displayName = user.name ?: &apos;Anonymous&apos; 12Groovy支持*.展开运算符，一个集合使用展开运算符可以得到一个元素为原集合各个元素执行后面指定方法所得值的集合，如下：cars = [ new Car(make: &apos;Peugeot&apos;, model: &apos;508&apos;), null, new Car(make: &apos;Renault&apos;, model: &apos;Clio&apos;)]assert cars*.make == [&apos;Peugeot&apos;, null, &apos;Renault&apos;] assert null*.make == null 关于Groovy的其他运算符就不多说，类比Java吧。 程序结构这里主要讨论Groovy的代码组成结构，具体如下细则。 包名包名的定义和作用及含义完全和Java一样，不再介绍，如下： 12// defining a package named com.yoursitepackage com.yoursite Imports引入常规的imports导包操作和Java一样，如下： 1234567891011121314151617181920212223//例1：import groovy.xml.MarkupBuilder// using the imported class to create an objectdef xml = new MarkupBuilder()assert xml != null//例2：import groovy.xml.*def markupBuilder = new MarkupBuilder()assert markupBuilder != nullassert new StreamingMarkupBuilder() != null//例3：import static Boolean.FALSEassert !FALSE//例4：特殊的，相当于用as取别名import static Calendar.getInstance as nowassert now().class == Calendar.getInstance().class 不过要特别注意，Groovy与Java类似，已经帮我们默认导入了一些常用的包，所以在我们使用这些包的类时就不用再像上面那样导入了，如下是自动导入的包列表： 12345678import java.lang.*import java.util.*import java.io.*import java.net.*import groovy.lang.*import groovy.util.*import java.math.BigIntegerimport java.math.BigDecimal 脚本与类（脚本的实质）相对于传统的Java类，一个包含main方法的Groovy类可以如下书写： 123456class Main &#123; static void main(String... args) &#123; println &apos;Groovy world!&apos; &#125;&#125;1 和Java一样，程序会从这个类的main方法开始执行，这是Groovy代码的一种写法，实际上执行Groovy代码完全可以不需要类或main方法，所以更简单的写法如下： 1234567891011121314151617println &apos;Groovy world!&apos;1上面这两中写法其实是一样的，具体我们可以通过如下命令进行编译为class文件：groovyc demo.groovy //编译Groovy源码为class1我们使用反编译工具可以查看到这个demo.groovy类源码如下：import org.codehaus.groovy.runtime.InvokerHelperclass Main extends Script &#123; def run() &#123; println &apos;Groovy world!&apos; &#125; static void main(String[] args) &#123; InvokerHelper.runScript(Main, args) &#125;&#125; 可以看见，上面我们写的groovy文件编译后的class其实是Java类，该类从Script类派生而来（查阅API）；可以发现，每个脚本都会生成一个static main方法，我们执行groovy脚本的实质其实是执行的这个Java类的main方法，脚本源码里所有代码都被放到了run方法中，脚本中定义的方法（该例暂无）都会被定义在Main类中。 通过上面可以发现，Groovy的实质就是Java的class，也就是说他一定会和Java一样存在变量作用域！对哦，前面我们解释变量时竟然没说到这个东东，这里说下吧。看下面例子： 1234567891011121314151617//单个Groovy源码文件，运行会报错找不到num变量def num = 1 def printNum()&#123; println num &#125;//单个Groovy源码文件，运行会报错找不到num变量int num = 1 def printNum()&#123; println num &#125; //单个Groovy源码文件，运行OK成功num = 1 def printNum()&#123; println num &#125; 上面的例子可以发现，我们如果想要在Groovy的方法中使用Groovy的变量则不能有修饰符。然而，如果我们想在B.groovy文件访问A.groovy文件的num变量咋办呢，我们可以使用Field注解，具体操作如下： 1234import groovy.transform.Field;@Field num = 112 哈哈，这就是Groovy的变量作用域了，如果你想知道上面这些写法为啥出错，很简单，自己动手整成Java源码相信你一定可以看懂为啥鸟。 闭包Groovy的闭包（closure）是一个非常重要的概念，闭包是可以用作方法参数的代码块，Groovy的闭包更象是一个代码块或者方法指针，代码在某处被定义然后在其后的调用处执行。 语法定义一个闭包： 123&#123; [closureParameters -&gt; ] statements &#125;//[closureparameters -&gt; ]是可选的逗号分隔的参数列表，参数类似于方法的参数列表，这些参数可以是类型化或非类型化的。 如下给出几个有效的闭包定义例子： 12345678910111213141516171819//最基本的闭包&#123; item++ &#125; //使用-&gt;将参数与代码分离&#123; -&gt; item++ &#125; //使用隐含参数it（后面有介绍）&#123; println it &#125; //使用明确的参数it替代&#123; it -&gt; println it &#125; //使用显示的名为参数&#123; name -&gt; println name &#125; //接受两个参数的闭包&#123; String x, int y -&gt; println &quot;hey $&#123;x&#125; the value is $&#123;y&#125;&quot;&#125;//包含一个参数多个语句的闭包&#123; reader -&gt; def line = reader.readLine() line.trim()&#125; 闭包对象： 一个闭包其实就是一个groovy.lang.Closure类型的实例，如下： //定义一个Closure类型的闭包 1234567def listener = &#123; e -&gt; println &quot;Clicked on $e.source&quot; &#125; assert listener instanceof Closure//定义直接指定为Closure类型的闭包Closure callback = &#123; println &apos;Done!&apos; &#125; Closure&lt;Boolean&gt; isTextFile = &#123; File it -&gt; it.name.endsWith(&apos;.txt&apos;) &#125; 调运闭包： 其实闭包和C语言的函数指针非常像，我们定义好闭包后调用的方法有如下两种形式： 闭包对象.call(参数) 闭包对象(参数) 如下给出例子： 1234567def code = &#123; 123 &#125;assert code() == 123assert code.call() == 123def isOdd = &#123; int i-&gt; i%2 == 1 &#125; assert isOdd(3) == true assert isOdd.call(2) == false 特别注意，如果闭包没定义参数则默认隐含一个名为it的参数，如下例子： 123def isEven = &#123; it%2 == 0 &#125; assert isEven(3) == false assert isEven.call(2) == true 参数普通参数： 一个闭包的普通参数定义必须遵循如下一些原则： 参数类型可选参数名字可选的参数默认值参数必须用逗号分隔如下是一些例子： 1234567891011121314151617def closureWithOneArg = &#123; str -&gt; str.toUpperCase() &#125;assert closureWithOneArg(&apos;groovy&apos;) == &apos;GROOVY&apos;def closureWithOneArgAndExplicitType = &#123; String str -&gt; str.toUpperCase() &#125;assert closureWithOneArgAndExplicitType(&apos;groovy&apos;) == &apos;GROOVY&apos;def closureWithTwoArgs = &#123; a,b -&gt; a+b &#125;assert closureWithTwoArgs(1,2) == 3def closureWithTwoArgsAndExplicitTypes = &#123; int a, int b -&gt; a+b &#125;assert closureWithTwoArgsAndExplicitTypes(1,2) == 3def closureWithTwoArgsAndOptionalTypes = &#123; a, int b -&gt; a+b &#125;assert closureWithTwoArgsAndOptionalTypes(1,2) == 3def closureWithTwoArgAndDefaultValue = &#123; int a, int b=2 -&gt; a+b &#125;assert closureWithTwoArgAndDefaultValue(1) == 3 隐含参数： 1234567891011121314151617当一个闭包没有显式定义一个参数列表时，闭包总是有一个隐式的it参数。如下：def greeting = &#123; &quot;Hello, $it!&quot; &#125;assert greeting(&apos;Patrick&apos;) == &apos;Hello, Patrick!&apos;12上面的类似下面这个例子：def greeting = &#123; it -&gt; &quot;Hello, $it!&quot; &#125;assert greeting(&apos;Patrick&apos;) == &apos;Hello, Patrick!&apos;12当然啦，如果你想声明一个不接受任何参数的闭包，且必须限定为没有参数的调用，那么你必须将它声明为一个空的参数列表，如下：def magicNumber = &#123; -&gt; 42 &#125;// this call will fail because the closure doesn&apos;t accept any argumentmagicNumber(11) 可变长参数： 1234567891011Groovy的闭包支持最后一个参数为不定长可变长度的参数，具体用法如下：def concat1 = &#123; String... args -&gt; args.join(&apos;&apos;) &#125; assert concat1(&apos;abc&apos;,&apos;def&apos;) == &apos;abcdef&apos; def concat2 = &#123; String[] args -&gt; args.join(&apos;&apos;) &#125; assert concat2(&apos;abc&apos;, &apos;def&apos;) == &apos;abcdef&apos;def multiConcat = &#123; int n, String... args -&gt; args.join(&apos;&apos;)*n&#125;assert multiConcat(2, &apos;abc&apos;,&apos;def&apos;) == &apos;abcdefabcdef&apos; 闭包省略调运很多方法的最后一个参数都是一个闭包，我们可以在这样的方法调运时进行略写括弧。比如： 1234567def debugClosure(int num, String str, Closure closure)&#123; //dosomething &#125; debugClosure(1, &quot;groovy&quot;, &#123; println&quot;hello groovy!&quot; &#125;) 可以看见，当闭包作为闭包或方法的最后一个参数时我们可以将闭包从参数圆括号中提取出来接在最后，如果闭包是唯一的一个参数，则闭包或方法参数所在的圆括号也可以省略；对于有多个闭包参数的，只要是在参数声明最后的，均可以按上述方式省略。 GDK(Groovy Development Kit)Groovy除了可以直接使用Java的JDK以外还有自己的一套GDK，其实也就是对JDK的一些类的二次封装罢了；一样，这是GDK官方API文档，写代码中请自行查阅。 I/O操作Groovy提供了很多IO操作的方法，你可以使用Java的那写IO方法，但是没有Groovy的GDK提供的简单牛逼。 读文件操作： 我们先来看一个例子： 123456789//读文件打印脚本new File(&apos;/home/temp&apos;, &apos;haiku.txt&apos;).eachLine &#123; line -&gt; println line&#125;//读文件打印及打印行号脚本new File(baseDir, &apos;haiku.txt&apos;).eachLine &#123; line, nb -&gt; println &quot;Line $nb: $line&quot;&#125; 可以看见，这是一个读文件打印每行的脚本，eachLine方法是GDK中File的方法，eachLine的参数是一个闭包，这里采用了简写省略括弧。 当然了，有时候你可能更加喜欢用Reader来操作，使用Reader时即使抛出异常也会自动关闭IO。如下： 12345678def count = 0, MAXSIZE = 3new File(baseDir,&quot;haiku.txt&quot;).withReader &#123; reader -&gt; while (reader.readLine()) &#123; if (++count &gt; MAXSIZE) &#123; throw new RuntimeException(&apos;Haiku should only have 3 verses&apos;) &#125; &#125;&#125; 接着我们再看几个关于读文件的操作使用，如下： 12345678910111213141516//把读到的文件行内容全部存入List列表中def list = new File(baseDir, &apos;haiku.txt&apos;).collect &#123;it&#125;//把读到的文件行内容全部存入String数组列表中def array = new File(baseDir, &apos;haiku.txt&apos;) as String[]//把读到的文件内容全部转存为byte数组byte[] contents = file.bytes//把读到的文件转为InputStream，切记此方式需要手动关闭流def is = new File(baseDir,&apos;haiku.txt&apos;).newInputStream()// do something ...is.close()//把读到的文件以InputStream闭包操作，此方式不需要手动关闭流new File(baseDir,&apos;haiku.txt&apos;).withInputStream &#123; stream -&gt; // do something ...&#125; 上面介绍了一些常用的文件读操作，其它的具体参见API和GDK吧。 写文件操作： 有了上面的读操作，接下来直接看几个写操作的例子得了，如下： 1234567891011121314151617181920//向一个文件以utf-8编码写三行文字new File(baseDir,&apos;haiku.txt&apos;).withWriter(&apos;utf-8&apos;) &#123; writer -&gt; writer.writeLine &apos;Into the ancient pond&apos; writer.writeLine &apos;A frog jumps&apos; writer.writeLine &apos;Water’s sound!&apos;&#125;//上面的写法可以直接替换为此写法new File(baseDir,&apos;haiku.txt&apos;) &lt;&lt; &apos;&apos;&apos;Into the ancient pondA frog jumpsWater’s sound!&apos;&apos;&apos;//直接以byte数组形式写入文件file.bytes = [66,22,11]//类似上面读操作，可以使用OutputStream进行输出流操作，记得手动关闭def os = new File(baseDir,&apos;data.bin&apos;).newOutputStream()// do something ...os.close()//类似上面读操作，可以使用OutputStream闭包进行输出流操作，不用手动关闭new File(baseDir,&apos;data.bin&apos;).withOutputStream &#123; stream -&gt; // do something ...&#125; 上面介绍了一些常用的文件写操作，其它的具体参见API和GDK吧。 文件树操作： 在脚本环境中，遍历一个文件树是很常见的需求，Groovy提供了多种方法来满足这个需求。如下： 12345678910111213141516171819202122232425//遍历所有指定路径下文件名打印dir.eachFile &#123; file -&gt; println file.name&#125;//遍历所有指定路径下符合正则匹配的文件名打印dir.eachFileMatch(~/.*\\.txt/) &#123; file -&gt; println file.name&#125;//深度遍历打印名字dir.eachFileRecurse &#123; file -&gt; println file.name&#125;//深度遍历打印名字，只包含文件类型dir.eachFileRecurse(FileType.FILES) &#123; file -&gt; println file.name&#125;//允许设置特殊标记规则的遍历操作dir.traverse &#123; file -&gt; if (file.directory &amp;&amp; file.name==&apos;bin&apos;) &#123; FileVisitResult.TERMINATE &#125; else &#123; println file.name FileVisitResult.CONTINUE &#125;&#125; 执行外部程序： Groovy提供一种简单方式来处理执行外部命令行后的输出流操作。如下： 1234def process = &quot;ls -l&quot;.execute() println &quot;Found text $&#123;process.text&#125;&quot;12 execute方法返回一个java.lang.Process对象，支持in、out、err的信息反馈。在看一个例子，如下： 1234def process = &quot;ls -l&quot;.execute() process.in.eachLine &#123; line -&gt; println line &#125; 上面使用闭包操作打印出执行命令行的输入流信息。 有用的工具类操作ConfigSlurper配置：ConfigSlurper是一个配置管理文件读取工具类，类似于Java的*.properties文件，如下： 1234567891011def config = new ConfigSlurper().parse(&apos;&apos;&apos; app.date = new Date() app.age = 42 app &#123; name = &quot;Test$&#123;42&#125;&quot; &#125;&apos;&apos;&apos;)assert config.app.date instanceof Dateassert config.app.age == 42assert config.app.name == &apos;Test42&apos; 上面介绍了一些常用的属性配置操作，其它的具体参见API和GDK吧。 Expando扩展：123456def expando = new Expando()expando.toString = &#123; -&gt; &apos;John&apos; &#125;expando.say = &#123; String s -&gt; &quot;John says: $&#123;s&#125;&quot; &#125;assert expando as String == &apos;John&apos;assert expando.say(&apos;Hi&apos;) == &apos;John says: Hi&apos; 上面介绍了一些常用的拓展操作，其它的具体参见API和GDK吧。 其他操作还有很多其他操作，这里就不一一列举，详情参考官方文档即可，譬如JSON处理、XML解析啥玩意的，自行需求摸索吧。 DSL(Domain Specific Languages)领域相关语言这个就不特殊说明了，只在这里提一下，因为我们前边很多地方已经用过它了，加上我们只是干货基础掌握，所以不做深入探讨。 DSL是一种特定领域的语言（功能领域、业务领域），Groovy是通用的编程语言，所以不是DSL，但是Groovy却对编写全新的DSL提供了很好的支持，这些支持来自于Groovy自身语法的特性，如下： Groovy不需用定义CLASS类就可以直接执行脚本； Groovy语法省略括弧和语句结尾分号等操作； 所以说这个基础入门没必要特别深入理解，简单的前面都用过了，理解DSL作用即可，点到为止，详情参考官方文档。 Groovy脚本基础总结其实没啥总结的，Groovy其实可以当做Java来看待，只是它提供的支持比Java还好而已，在学习Groovy是一定要和Java进行对比学习，这样才能速成基础。","categories":[],"tags":[{"name":"CI-CD","slug":"CI-CD","permalink":"https://banghuaji.github.io/tags/CI-CD/"},{"name":"GROOVY","slug":"GROOVY","permalink":"https://banghuaji.github.io/tags/GROOVY/"}]},{"title":"VPS，虚拟主机，云主机，独立服务器","slug":"cloud-service/VPS，虚拟主机，云主机，独立服务器","date":"2017-11-02T14:17:28.968Z","updated":"2017-11-02T14:15:35.430Z","comments":true,"path":"2017/11/02/cloud-service/VPS，虚拟主机，云主机，独立服务器/","link":"","permalink":"https://banghuaji.github.io/2017/11/02/cloud-service/VPS，虚拟主机，云主机，独立服务器/","excerpt":"","text":"独立服务器 独立服务器，顾名思义，就是一个躺在机房的实实在在的物理服务器，也可理解为你的游戏主机一样。 优点：性能高 缺点：价格高，高可用性低（比如断电，硬盘坏了……） VPS Virtual Private Server 虚拟专用服务器,一般是将一个独立服务器通过虚拟化技术虚拟成多个虚拟专用服务器。 优点：价格便宜缺点：性能低，高可用性低（除了其所在的物理机出问题了会收到影响，虚拟化技术出问题也会收到影响） 云服务器 Elastic Compute Service, 简称ECS 好多人理解云服务器和VPS一样，更有甚者说以前的VPS现在的说法就是云服务器，其实不然，云服务器是一个计算，网络，存储的组合。简单点说就是通过多个CPU，内存，硬盘组成的计算池和存储池和网络的组合。 优点：价格适中，使用灵活，高可用性（单个或多个物理离线不会对整个服务造成太大的影响） 缺点：性能相对较低 虚拟主机Virtual hosts （Vhost）虚拟主机是通过，物理服务器，VPS或者云服务器安装例如CPanel，Plesk等面板搭建的。 总结：如过只是做一个小网站，个人博客等用虚拟主机就可，大点的应用建议用云服务器 虚拟主机市场比较混乱，不同的厂商价格一般会有很大的差异，一般来说看一个虚拟主机的好坏可以从以下几点来看， 主机系统：CloudLinux 更适合多租户虚拟主机，CPanel，Plesk 面板在市场上最受市场欢迎， 一般来说价格相对较贵，使用云服务器最好（比如阿里云），物理服务器也可，一般不选择VPS作为虚拟主机的服务器。 优点：价格低，使用方便缺点：一般来说只能做网站，或应用后端服务器，市场杂乱比较难选购","categories":[],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://banghuaji.github.io/tags/服务器/"}]},{"title":"LINUX实现免密钥登陆","slug":"soft/LINUX实现免密钥登陆","date":"2017-11-02T14:11:17.845Z","updated":"2017-05-25T07:31:25.000Z","comments":true,"path":"2017/11/02/soft/LINUX实现免密钥登陆/","link":"","permalink":"https://banghuaji.github.io/2017/11/02/soft/LINUX实现免密钥登陆/","excerpt":"","text":"github 或者gitlab 设置添加SSH, 避免每次提交重复输入用户名克隆项目二种方式： 使用https url克隆, 复制https url 然后到 git clone https-url 使用 SSH url克隆却需要在克隆之前先配置和添加好 SSH key, 你必须是这个项目的拥有者。否则你是无法添加 SSH key 的。 https 和 SSH 的区别：1、前者可以随意克隆github上的项目，而不管是谁的；而后者则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。 2、https url 在push的时候是需要验证用户名和密码的；而 SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。 在 github 上添加 SSH key 的步骤：1、首先需要检查你电脑是否已经有 SSH key 运行 git Bash 客户端，输入如下代码： 12$ cd ~/.ssh$ ls 这两个命令就是检查是否已经存在 id_rsa.pub 或 id_dsa.pub 文件，如果文件已经存在，那么你可以跳过步骤2，直接进入步骤3。 2、创建一个 SSH key 1$ ssh-keygen -t rsa -C \"your_email@example.com\" 代码参数含义： -t 指定密钥类型，默认是 rsa ，可以省略。-C 设置注释文字，比如邮箱。-f 指定密钥文件存储文件名。 以上代码省略了 -f 参数，因此，运行上面那条命令后会让你输入一个文件名，用于保存刚才生成的 SSH key 代码，如： Generating public/private rsa key pair. Enter file in which to save the key (/c/Users/you/.ssh/id_rsa): [Press enter]当然，你也可以不输入文件名，使用默认文件名（推荐），那么就会生成 id_rsa 和 id_rsa.pub 两个秘钥文件。 接着又会提示你输入两次密码（该密码是你push文件的时候要输入的密码，而不是github管理者的密码）， 当然，你也可以不输入密码，直接按回车。那么push的时候就不需要输入密码，直接提交到github上了，如： Enter passphrase (empty for no passphrase): Enter same passphrase again:接下来，就会显示如下代码提示，如： 1234Your identification has been saved in /c/Users/you/.ssh/id_rsa.# Your public key has been saved in /c/Users/you/.ssh/id_rsa.pub.# The key fingerprint is:# 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@example.com 当你看到上面这段代码的收，那就说明，你的 SSH key 已经创建成功，你只需要添加到github的SSH key上就可以了。 3、添加你的 SSH key 到 github上面去 a、首先你需要拷贝 id_rsa.pub 文件的内容，你可以用编辑器打开文件复制，也可以用git命令复制该文件的内容，如： $ clip &lt; ~/.ssh/id_rsa.pubb、登录你的github账号，从又上角的设置（ Account Settings ）进入，然后点击菜单栏的 SSH key 进入页面添加 SSH key。 c、点击 Add SSH key 按钮添加一个 SSH key 。把你复制的 SSH key 代码粘贴到 key 所对应的输入框中，记得 SSH key 代码的前后不要留有空格或者回车。当然，上面的 Title 所对应的输入框你也可以输入一个该 SSH key 显示在 github 上的一个别名。默认的会使用你的邮件名称。 4、测试一下该SSH key 在git Bash 中输入以下代码 $ ssh -T git@github.com当你输入以上代码时，会有一段警告代码，如： The authenticity of host ‘github.com (207.97.227.239)’ can’t be established. RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48. Are you sure you want to continue connecting (yes/no)?这是正常的，你输入 yes 回车既可。如果你创建 SSH key 的时候设置了密码，接下来就会提示你输入密码，如： Enter passphrase for key ‘/c/Users/Administrator/.ssh/id_rsa’:当然如果你密码输错了，会再要求你输入，知道对了为止。 注意：输入密码时如果输错一个字就会不正确，使用删除键是无法更正的。 密码正确后你会看到下面这段话，如： Hi username! You’ve successfully authenticated, but GitHub does not provide shell access.如果用户名是正确的,你已经成功设置SSH密钥。如果你看到 “access denied” ，者表示拒绝访问，那么你就需要使用 https 去访问，而不是 SSH 。","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://banghuaji.github.io/tags/工具/"},{"name":"GIT","slug":"GIT","permalink":"https://banghuaji.github.io/tags/GIT/"}]},{"title":"GIT安装与使用","slug":"soft/GIT安装与使用","date":"2017-11-02T14:11:17.812Z","updated":"2017-11-02T14:12:09.971Z","comments":true,"path":"2017/11/02/soft/GIT安装与使用/","link":"","permalink":"https://banghuaji.github.io/2017/11/02/soft/GIT安装与使用/","excerpt":"","text":"一、安装Git（windows版、其他平台参阅） 去Git的官网，下载安装包，安装时，一路默认https://git-scm.com/download/win 二、配置Git 2.1 在任意地方，创建一个文件夹，保证该文件夹的目录全部是英文 2.2 打开新建的文件夹，在空白处右击，菜单中点选 Git Init Here 2.3 再次右击，菜单中点选Git Bash，弹出命令行 2.4 配置所有本地仓的账号、邮箱 12$ git config --global user.name \"Your Name\" $ git config --global user.email \"email@example.com\" 2.5 为避免每次远程访问输入密码，使用ssh登陆。ssh应该是与本机信息绑定的，所以每台电脑需要单独生成。 1$ ssh-keygen -t rsa -C \"youremail@example.com\" 2.6 ssh只是本地详细，需要在GitLab中备份，才能被验证。打开自己的GitLab，在My Profile中，点击Add Public Key，title随意。 2.7 key中的内容在本机C盘中，C:\\Users\\account（你的账户下），里面有个.ssh文件夹（运行2.5会产生），用文本文档打开id_rsa.pub，将里面的内容全部复制到key中，即可； 2.8 到此，基本配置完毕；我们需要获取GitLab上项目的地址，每个项目地址不同，一般在GitLab的Projects中，能找到跟你相关的所有项目，点开一个项目，就能看到项目地址，然后在Git Bash中输入： 1$ git clone git@github.com:michaelliao/gitskills.git 2.9 在克隆仓库时，Git 通常会自动创建一个名为 master 的分支来跟踪 origin/master，如果需要关联不同的分支，使用命令 1$ git checkout --track origin/br-2.1.2.1 2.10 将数据同步到本地，一般关联后，直接: 1$ git pull 即可完成项目的拉取至此，我们完成了一个在GitLab上的项目，到本地的过程。 More info: 廖雪峰的官方网站","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://banghuaji.github.io/tags/工具/"},{"name":"GIT","slug":"GIT","permalink":"https://banghuaji.github.io/tags/GIT/"}]},{"title":"groovy基础","slug":"language/groovy/groovy语法","date":"2017-10-29T15:54:55.583Z","updated":"2017-10-31T14:58:54.937Z","comments":true,"path":"2017/10/29/language/groovy/groovy语法/","link":"","permalink":"https://banghuaji.github.io/2017/10/29/language/groovy/groovy语法/","excerpt":"","text":"安装groovy：12345wget https://dl.bintray.com/groovy/maven/apache-groovy-binary-2.4.7.zipunzip apache-groovy-binary-2.4.7.zipsudo ln -s /home/osboxes/Downloads/groovy-2.4.7/bin/groovy /usr/bin/groovygroovy -vGroovy Version: 2.4.7 JVM: 1.8.0_91 Vendor: Oracle Corporation OS: Linux 基础语法123456789101112131415161718192021#!/usr/bin/env groovy // Hello Worldprintln &quot;Hello world!&quot; // Variables: You can assign values to variables for later usedef x = 1println x x = new java.util.Date()println x x = -3.1499392println x x = falseprintln x x = &quot;Groovy!&quot;println x 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178//Creating an empty listdef technologies = [] /*** Adding a elements to the list ***/// As with Javatechnologies.add(&quot;Grails&quot;) // Left shift adds, and returns the listtechnologies &lt;&lt; &quot;Groovy&quot; // Add multiple elementstechnologies.addAll([&quot;Gradle&quot;,&quot;Griffon&quot;]) /*** Removing elements from the list ***/// As with Javatechnologies.remove(&quot;Griffon&quot;) // Subtraction works alsotechnologies = technologies - &apos;Grails&apos; /*** Iterating Lists ***/// Iterate over elements of a listtechnologies.each &#123; println &quot;Technology: $it&quot;&#125;technologies.eachWithIndex &#123; it, i -&gt; println &quot;$i: $it&quot;&#125; /*** Checking List contents ***///Evaluate if a list contains element(s) (boolean)contained = technologies.contains( &apos;Groovy&apos; ) // Orcontained = &apos;Groovy&apos; in technologies // Check for multiple contentstechnologies.containsAll([&apos;Groovy&apos;,&apos;Grails&apos;]) /*** Sorting Lists ***/ // Sort a list (mutates original list)technologies.sort() // To sort without mutating original, you can do:sortedTechnologies = technologies.sort( false ) /*** Manipulating Lists ***/ //Replace all elements in the listCollections.replaceAll(technologies, &apos;Gradle&apos;, &apos;gradle&apos;) //Shuffle a listCollections.shuffle(technologies, new Random()) //Clear a listtechnologies.clear() //Creating an empty mapdef devMap = [:] //Add valuesdevMap = [&apos;name&apos;:&apos;Roberto&apos;, &apos;framework&apos;:&apos;Grails&apos;, &apos;language&apos;:&apos;Groovy&apos;]devMap.put(&apos;lastName&apos;,&apos;Perez&apos;) //Iterate over elements of a mapdevMap.each &#123; println &quot;$it.key: $it.value&quot; &#125;devMap.eachWithIndex &#123; it, i -&gt; println &quot;$i: $it&quot;&#125; //Evaluate if a map contains a keyassert devMap.containsKey(&apos;name&apos;) //Evaluate if a map contains a valueassert devMap.containsValue(&apos;Roberto&apos;) //Get the keys of a mapprintln devMap.keySet() //Get the values of a mapprintln devMap.values() //Groovy supports the usual if - else syntaxdef x1 = 3 if(x1==1) &#123; println &quot;One&quot;&#125; else if(x1==2) &#123; println &quot;Two&quot;&#125; else &#123; println &quot;X greater than Two&quot;&#125; //Groovy also supports the ternary operator:def y = 10def x2 = (y &gt; 1) ? &quot;worked&quot; : &quot;failed&quot;assert x2 == &quot;worked&quot; //Instead of using the ternary operator://displayName = user.name ? user.name : &apos;Anonymous&apos;//We can write it://displayName = user.name ?: &apos;Anonymous&apos; //For loop//Iterate over a rangedef x3 = 0for (i in 0 .. 30) &#123; x3 += i&#125; //Iterate over a listx4 = 0for( i in [5,3,2,1] ) &#123; x4 += i&#125; //Iterate over an arrayarray = (0..20).toArray()x5 = 0for (i in array) &#123; x5 += i&#125; //Iterate over a mapdef map = [&apos;name&apos;:&apos;Roberto&apos;, &apos;framework&apos;:&apos;Grails&apos;, &apos;language&apos;:&apos;Groovy&apos;]x6 = 0for ( e in map ) &#123; x6 += e.value&#125; /* Closures A Groovy Closure is like a &quot;code block&quot; or a method pointer. It is a piece of code that is defined and then executed at a later point. More info at: http://www.groovy-lang.org/closures.html*/ //Example:def clos = &#123; println &quot;Hello World!&quot; &#125; println &quot;Executing the Closure:&quot;clos() //Passing parameters to a closuredef sum = &#123; a, b -&gt; println a+b &#125;sum(2,4) //Closures may refer to variables not listed in their parameter list.def x7 = 5def multiplyBy = &#123; num -&gt; num * x7 &#125;println multiplyBy(10) // If you have a Closure that takes a single argument, you may omit the// parameter definition of the Closuredef clos2 = &#123; println it &#125;clos2( &quot;hi&quot; ) /* Groovy can memoize closure results [1][2][3]*/def cl = &#123;a, b -&gt; sleep(3000) // simulate some time consuming processing a + b&#125; mem = cl.memoize() def callClosure(a, b) &#123; def start = System.currentTimeMillis() println mem(a, b) println &quot;Inputs(a = $a, b = $b) - took $&#123;System.currentTimeMillis() - start&#125; msecs.&quot;&#125; callClosure(1, 2)callClosure(1, 2)callClosure(2, 3)callClosure(2, 3)callClosure(3, 4)callClosure(3, 4)callClosure(1, 2)callClosure(2, 3)callClosure(3, 4)","categories":[],"tags":[{"name":"CI-CD","slug":"CI-CD","permalink":"https://banghuaji.github.io/tags/CI-CD/"}]},{"title":"pipeline的基础语法","slug":"language/pipeline/pipeline的基础语法","date":"2017-10-29T11:28:47.096Z","updated":"2017-10-29T11:17:52.000Z","comments":true,"path":"2017/10/29/language/pipeline/pipeline的基础语法/","link":"","permalink":"https://banghuaji.github.io/2017/10/29/language/pipeline/pipeline的基础语法/","excerpt":"","text":"命令的执行步骤123456789101112131415Jenkinsfile (Declarative Pipeline)pipeline &#123; agent any stages &#123; stage(&apos;Build&apos;) &#123; steps &#123; sh &apos;echo &quot;Hello World&quot;&apos; sh &apos;&apos;&apos; echo &quot;Multiline shell steps works too&quot; ls -lah &apos;&apos;&apos; &#125; &#125; &#125;&#125; 重试与超时1234567891011121314151617Jenkinsfile (Declarative Pipeline)pipeline &#123; agent any stages &#123; stage(&apos;Deploy&apos;) &#123; steps &#123; retry(3) &#123; sh &apos;./flakey-deploy.sh&apos; &#125; timeout(time: 3, unit: &apos;MINUTES&apos;) &#123; sh &apos;./health-check.sh&apos; &#125; &#125; &#125; &#125;&#125; 123456789101112131415Jenkinsfile (Declarative Pipeline)pipeline &#123; agent any stages &#123; stage(&apos;Deploy&apos;) &#123; steps &#123; timeout(time: 3, unit: &apos;MINUTES&apos;) &#123; retry(5) &#123; sh &apos;./flakey-deploy.sh&apos; &#125; &#125; &#125; &#125; &#125;&#125; 完成1234567891011121314151617181920212223242526272829Jenkinsfile (Declarative Pipeline)pipeline &#123; agent any stages &#123; stage(&apos;Test&apos;) &#123; steps &#123; sh &apos;echo &quot;Fail!&quot;; exit 1&apos; &#125; &#125; &#125; post &#123; always &#123; echo &apos;This will always run&apos; &#125; success &#123; echo &apos;This will run only if successful&apos; &#125; failure &#123; echo &apos;This will run only if failed&apos; &#125; unstable &#123; echo &apos;This will run only if the run was marked as unstable&apos; &#125; changed &#123; echo &apos;This will run only if the state of the Pipeline has changed&apos; echo &apos;For example, if the Pipeline was previously failing but is now successful&apos; &#125; &#125;&#125; 12345678post &#123; always &#123; echo &apos;This will always run&apos; mail to: &apos;YYYY@yoho.cn&apos;, subject: &quot;Failed Pipeline: $&#123;currentBuild.fullDisplayName&#125; ,&amp;&amp; state is $&#123;currentBuild.currentResult&#125;&quot;, body: &quot;Something is wrong with $&#123;env.BUILD_URL&#125;&quot; &#125;&#125; 要求人力投入进行1234567891011121314151617181920212223242526Jenkinsfile (Declarative Pipeline)pipeline &#123; agent any stages &#123; /* &quot;Build&quot; and &quot;Test&quot; stages omitted */ stage(&apos;Deploy - Staging&apos;) &#123; steps &#123; sh &apos;./deploy staging&apos; sh &apos;./run-smoke-tests&apos; &#125; &#125; stage(&apos;Sanity check&apos;) &#123; steps &#123; input &quot;Does the staging environment look ok?&quot; &#125; &#125; stage(&apos;Deploy - Production&apos;) &#123; steps &#123; sh &apos;./deploy production&apos; &#125; &#125; &#125;&#125; 在Pipeline示例的这个阶段，“构建”和“测试”阶段都已成功执行。实际上，“部署”阶段只能在上一阶段成功完成，否则Pipeline将早退。1234567891011121314151617Jenkinsfile (Declarative Pipeline)pipeline &#123; agent any stages &#123; stage(&apos;Deploy&apos;) &#123; when &#123; expression &#123; currentBuild.result == null || currentBuild.result == &apos;SUCCESS&apos; &#125; &#125; steps &#123; sh &apos;make publish&apos; &#125; &#125; &#125;&#125; parallel来使得任务并行地执行1234567891011121314151617181920stage(&apos;test&apos;) &#123; steps &#123; script &#123; parallel ( aaa : &#123; build_if_needed(&apos;aaa&apos;)&#125;, bbb : &#123; build_if_needed(&apos;bbb&apos;)&#125;, ccc : &#123; build_if_needed(&apos;ccc&apos;)&#125;, ddd : &#123; build_if_needed(&apos;ddd&apos;)&#125;, eee : &#123; build_if_needed(&apos;eee&apos;)&#125; ) parallel ( fff : &#123; build_if_needed(&apos;fff&apos;)&#125;, ggg : &#123; build_if_needed(&apos;ggg&apos;)&#125;, hhh : &#123; build_if_needed(&apos;hhh&apos;)&#125;, jjj : &#123; build_if_needed(&apos;jjj&apos;)&#125;, kkk : &#123; build_if_needed(&apos;kkk&apos;)&#125; ) &#125; &#125;&#125; 12345678910111213stage(&apos;test&apos;) &#123; steps &#123; //echo &quot;steps parallel begin&quot; parallel ( aaa : &#123; build_if_needed(&apos;aaa&apos;)&#125;, bbb : &#123; build_if_needed(&apos;bbb&apos;)&#125;, ccc : &#123; build_if_needed(&apos;ccc&apos;)&#125;, ddd : &#123; build_if_needed(&apos;ddd&apos;)&#125;, eee : &#123; build_if_needed(&apos;eee&apos;)&#125; ) //echo &quot;steps parallel end&quot; &#125;&#125; 1234567891011stage(&apos;test&apos;) &#123; steps &#123; //echo &quot;steps parallel begin&quot; parallel firstBranch: &#123; echo &quot;*********** Starting Test&quot; &#125;, secondBranch: &#123; echo &quot;*********** Starting Test2&quot; &#125; //echo &quot;steps parallel end&quot; &#125;&#125; PS:注释采用// 这里面只能有一个step，否则不能够成功 选择对应的环境：12345parallel &apos;integration-tests&apos;:&#123; node(&apos;mvn-3.3&apos;)&#123; ... &#125;&#125;, &apos;functional-tests&apos;:&#123; node(&apos;selenium&apos;)&#123; ... &#125;&#125;","categories":[],"tags":[{"name":"CI-CD","slug":"CI-CD","permalink":"https://banghuaji.github.io/tags/CI-CD/"}]},{"title":"自动化目的以及答疑","slug":"autotest/自动化目的以及答疑","date":"2017-10-08T14:20:13.294Z","updated":"2017-10-08T14:20:05.000Z","comments":true,"path":"2017/10/08/autotest/自动化目的以及答疑/","link":"","permalink":"https://banghuaji.github.io/2017/10/08/autotest/自动化目的以及答疑/","excerpt":"","text":"自动化的目的 把测试从枯燥的重复劳动中解放出来，例如：回归测试等； 协助手工测试完成很难模拟或无法模拟的的工作，例如：篡改服务返回的数据验证前端对各种数据场景的处理，弱网模拟、特殊协议数据包解析验证等； 尽早发现Bug，例如：数据层的存储过程、Package批量调用验证、接口自动化等偏底层的问题； 协助定位问题，现在的自动化提出了更高的要求，例如：接口层发现问题了，可以通过添加的traceID定位到日志错误或错误代码行，app运行中异常可捕获错误日志等； 线上监控报警，现在的自动化不仅限于线下，线上的也已覆盖，测试和运维的工作可能存在交集，我们不能把质量问题寄托于他人，一旦发现问题，立即报警通知到人，让损失到最小。 提高工作效率，这个面有点广，例如，测试环境的自动化编译、打包、部署、持续集成甚至持续交付等。 关于自动化介入的若干问题 是否要考虑成本？ 当然要考虑，我们总会遇到在成本和质量之间找平衡点，可能一些特殊的行业，特殊的项目，质量的权重更高点，如果引入自动化能提高质量，该介入的还是要介入。 是不是只有大公司能做， 小公司和初创公司就不适合搞自动化？这不是绝对的，还是要看公司的资源和人员配备，如果有能力做为什么不？况且小公司的自动化不一定要做到大公司的程度，只要能提高工作效率，提高质量就可以，滴水穿石，聚沙成塔。 自动化何时介入？ 条件许可的还是尽早介入，越是底层的Bug，影响面越广，修复成本也是最低的。但这不是硬性标准，一般公司都是从UI自动化开始积累经验的，拔苗不能助长。 如何开展自动化工作这个信息量比较大，人才和技术就不多说了，我更关心的是做事的方式 抓住业务测试工作中的痛点和领导的痛点，多沟通多交流，优先解决基层的工作痛点，我相信一个好的领导会看到你的责任心和付出； 技术选型和方案可行性调研，多投入时间和精力，有的人性子急，前期做的很快，如果一开始的方向错了，最终会得不偿失； 如果是比较复杂的解决方案，尽量前后端分离、保证各模块的独立性、可融合性、解耦不解体，做到灵活可扩展，要有下一盘大棋的准备。 大家的看法每个公司的所谓的管理层对自动化理解的层面可能不一样，需要根据实际情况来做自动化，至少中心点不能偏离，需要紧扣业务，另外就是要能实际落地，还有一个就是维护成本及投入产出比。 是否要考虑成本？ 当然要考虑，我们总会遇到在成本和质量之间找平衡点，可能一些特殊的行业，特殊的项目，质量的权重更高点，如果引入自动化能提高质量，该介入的还是要介入。抓住业务测试工作中的痛点和领导的痛点，多沟通多交流，优先解决基层的工作痛点，我相信一个好的领导会看到你的责任心和付出 个人的提问看到题主关于自动化的分享， 有几个延伸问题，自己在工作中一直思考，但是一直没有找到合适的答案。 接口自动化和UI自动化的用例是完全重新设计，还是从业务用例中筛选？IF从业务用例中筛选的话，筛选的标准有哪些呢？（PS：接口用例中的接口参数类型的用例设计，暂不考虑）接口自动化和UI自动化，互相之间有影响吗？或者说接口覆盖的用例和UI覆盖的用例之间是否有某种关联？IF有关联，请问需要多大粒度的关联比较合适？ELIF 没关联，请问两者之间各自为战吗？（PS：这样会不会导致测试覆盖率重复呢？）如果UI层的用例Faile，是不是需要定位到对应的接口层？相反，接口层用例faile，是否需要定位到UI层，IF 以上需要，如何有效关联呢？Or 是否需要在分层测试的工程中，让他们互相成为彼此的辅助？ 个人答案：接口自动化和UI自动化的用例是完全重新设计，还是从业务用例中筛选？IF从业务用例中筛选的话，筛选的标准有哪些呢？（PS：接口用例中的接口参数类型的用例设计，暂不考虑）－－我觉得接口自动化案例要重新设计，这里涉及到分层的概念，接口层更关注对数据的验证，处理各种请求参数正交场景下返回数据的正确性，涉及到增、删、改的接口还要关注数据落地的有效性。 接口自动化和UI自动化，互相之间有影响吗？或者说接口覆盖的用例和UI覆盖的用例之间是否有某种关联？IF有关联，请问需要多大粒度的关联比较合适？ELIF 没关联，请问两者之间各自为战吗？（PS：这样会不会导致测试覆盖率重复呢？）－－接口测试不一定和UI测试有关联，传统的接口测试，不需要等UI开发完成就可以介入了，从这点来说属于前置阶段的，通过Mock Client实现的接口测试；－－UI测试和接口测试一定有关联，因为UI层的数据渲染大部分是通过调用接口获取的，在执行UI自动化的同时，有很多眼睛看不到摸不着的接口在来回穿梭，这些不是Mock Client发起的，而是由真实的程序发起的，场景化内部的参数动态关联等一系列问题，程序都会帮你自动处理。所以由UI测试发起的接口测试，只要你能劫持到接口返回的报文，实现起来比传统的要简单多了。 如果UI层的用例Faile，是不是需要定位到对应的接口层？相反，接口层用例faile，是否需要定位到UI层，IF 以上需要，如何有效关联呢？Or 是否需要在分层测试的工程中，让他们互相成为彼此的辅助？－－UI层Fail，接口层不一定Fail，因为即便接口是正确的，也不能保证UI层的数据再处理不会犯错。相反，接口层Fail了，与之相关的UI层必定Fail。如果接口层Fail，我们可以通过一些手段，例如：获取接口关键字、定制traceID，通过这些唯一性标识去定位错误日志或代码行。 转载于Test-Home:quqing","categories":[],"tags":[{"name":"autotest","slug":"autotest","permalink":"https://banghuaji.github.io/tags/autotest/"}]},{"title":"jquery select2使用js赋值","slug":"full-stack/WEB/jquery select2使用js赋值","date":"2017-10-01T13:12:22.089Z","updated":"2017-10-01T13:12:21.000Z","comments":true,"path":"2017/10/01/full-stack/WEB/jquery select2使用js赋值/","link":"","permalink":"https://banghuaji.github.io/2017/10/01/full-stack/WEB/jquery select2使用js赋值/","excerpt":"","text":"但是遇到一个问题 jquery select2插件 取值和原来的select标签取值都一样。但是给jquery select2赋值就出现了问题，用传统的select赋值的方式给jquery select2赋值发现不起作用。 最后查看了jquery select2的api文档，也网上搜了很多资料，但是都给得jquery select2赋值方式是：$(“#id”).val(“1”).trigger(“change”); 我感觉这种赋值方式是有问题，虽然这样赋值也行，但我个人不推荐这样赋值，而是使用jquery select2 api 里提到的赋值方式：$(“#id”).val(“1”).select2(); 这样就可以了。","categories":[],"tags":[{"name":"WEB","slug":"WEB","permalink":"https://banghuaji.github.io/tags/WEB/"}]},{"title":"Docker安装与调试","slug":"deploy/docker/Docker(一)--安装","date":"2017-10-01T12:45:15.270Z","updated":"2017-06-13T02:58:32.000Z","comments":true,"path":"2017/10/01/deploy/docker/Docker(一)--安装/","link":"","permalink":"https://banghuaji.github.io/2017/10/01/deploy/docker/Docker(一)--安装/","excerpt":"","text":"linux—centos下面安装docker的官方安装文档：由docker给的文档可以看出它也只是去配置了一个docker的yum源、然后就通过这个源来安装docker了；在这个文档下我们采用手工配置 1https://docs.docker.com/engine/installation/linux/centos/ 必备条件1、LINUX centos 7以上可以通过1uname -r 1234567lsb_release -a[root@localhost docker]# lsb_release -aLSB Version: :core-4.1-amd64:core-4.1-noarchDistributor ID: CentOSDescription: CentOS Linux release 7.2.1511 (Core) Release: 7.2.1511Codename: Core 配置一个docker用的源：1、为docker 增加一个新的yum配置文件；1touch /etc/yum.repos.d/docker.repo 2、docker.repo的内容如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[docker-ce-stable]name=Docker CE Stable - $basearchbaseurl=https://download.docker.com/linux/centos/7/$basearch/stableenabled=1gpgcheck=0 #我把这里设置成了0、说明我信任了这个源，不对它的rpm进行检察gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-stable-debuginfo]name=Docker CE Stable - Debuginfo $basearchbaseurl=https://download.docker.com/linux/centos/7/debug-$basearch/stableenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-stable-source]name=Docker CE Stable - Sourcesbaseurl=https://download.docker.com/linux/centos/7/source/stableenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-edge]name=Docker CE Edge - $basearchbaseurl=https://download.docker.com/linux/centos/7/$basearch/edgeenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-edge-debuginfo]name=Docker CE Edge - Debuginfo $basearchbaseurl=https://download.docker.com/linux/centos/7/debug-$basearch/edgeenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-edge-source]name=Docker CE Edge - Sourcesbaseurl=https://download.docker.com/linux/centos/7/source/edgeenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-test]name=Docker CE Test - $basearchbaseurl=https://download.docker.com/linux/centos/7/$basearch/testenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-test-debuginfo]name=Docker CE Test - Debuginfo $basearchbaseurl=https://download.docker.com/linux/centos/7/debug-$basearch/testenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-test-source]name=Docker CE Test - Sourcesbaseurl=https://download.docker.com/linux/centos/7/source/testenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg 安装docker:12345678910111213141516171819202122232425262728sudo yum install docker-ceLoaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfileResolving Dependencies--&gt; Running transaction check---&gt; Package docker-ce.x86_64 0:17.03.1.ce-1.el7.centos will be installed--&gt; Processing Dependency: docker-ce-selinux &gt;= 17.03.1.ce-1.el7.centos for package: docker-ce-17.03.1.ce-1.el7.centos.x86_64--&gt; Running transaction check---&gt; Package docker-ce-selinux.noarch 0:17.03.1.ce-1.el7.centos will be installed--&gt; Finished Dependency ResolutionDependencies Resolved===================================================================================================================================== Package Arch Version Repository Size=====================================================================================================================================Installing: docker-ce x86_64 17.03.1.ce-1.el7.centos docker-ce-stable 19 MInstalling for dependencies: docker-ce-selinux noarch 17.03.1.ce-1.el7.centos docker-ce-stable 28 kTransaction Summary=====================================================================================================================================Install 1 Package (+1 Dependent package)Total download size: 19 MInstalled size: 19 MIs this ok [y/d/N]: y 直接下载rpm包的方式来安装1、我在安装docker的时候发现下载的速度只有3kB/s 然而文件大小有19M；就在我感觉安装无望的时候、我机智的想到了自己直接把rpm下载下来 看了下docker.repo 、发现centos7的源地址是 https://download.docker.com/linux/centos/7/$basearch/stable 所以我只要去1https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ 下载的文件需要注意的版本12docker-ce-17.03.0.ce-1.el7.centos.x86_64.rpm docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpm 安装docker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748lltotal 19096-rwxrwxrwx 1 jianglexing jianglexing 19521288 May 30 20:05 docker-ce-17.03.0.ce-1.el7.centos.x86_64.rpm-rw-r--r-- 1 jianglexing jianglexing 29108 May 30 20:15 docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpm[root@workstudio docker]# yum localinstall *Loaded plugins: fastestmirror, langpacksExamining docker-ce-17.03.0.ce-1.el7.centos.x86_64.rpm: docker-ce-17.03.0.ce-1.el7.centos.x86_64Marking docker-ce-17.03.0.ce-1.el7.centos.x86_64.rpm to be installedExamining docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpm: docker-ce-selinux-17.03.0.ce-1.el7.centos.noarchMarking docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpm to be installedResolving Dependencies--&gt; Running transaction check---&gt; Package docker-ce.x86_64 0:17.03.0.ce-1.el7.centos will be installed---&gt; Package docker-ce-selinux.noarch 0:17.03.0.ce-1.el7.centos will be installed--&gt; Finished Dependency ResolutionDependencies Resolved===================================================================================================================================== Package Arch Version Repository Size=====================================================================================================================================Installing: docker-ce x86_64 17.03.0.ce-1.el7.centos /docker-ce-17.03.0.ce-1.el7.centos.x86_64 65 M docker-ce-selinux noarch 17.03.0.ce-1.el7.centos /docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch 43 kTransaction Summary=====================================================================================================================================Install 2 PackagesTotal size: 65 MInstalled size: 65 MIs this ok [y/d/N]: yDownloading packages:Running transaction checkRunning transaction testTransaction test succeededRunning transaction Installing : docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch 1/2 setsebool: SELinux is disabled.libsemanage.semanage_direct_install_info: Overriding docker module at lower priority 100 with module at priority 400. Installing : docker-ce-17.03.0.ce-1.el7.centos.x86_64 2/2 Verifying : docker-ce-17.03.0.ce-1.el7.centos.x86_64 1/2 Verifying : docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch 2/2 Installed: docker-ce.x86_64 0:17.03.0.ce-1.el7.centos docker-ce-selinux.noarch 0:17.03.0.ce-1.el7.centos Complete! 启动DOCKER12345[root@workstudio docker]# systemctl start docker[root@workstudio docker]# ps -ef | grep dockerroot 4458 1 1 20:22 ? 00:00:00 /usr/bin/dockerdroot 4465 4458 0 20:22 ? 00:00:00 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --shim docker-containerd-shim --runtime docker-runcroot 4589 4333 0 20:22 pts/1 00:00:00 grep --color=auto docker 测试docker是否能成功运行有可能遇到无法下载的问题：需要多试几次，123Unable to find image &apos;hello-world:latest&apos; locallydocker: Error response from daemon: Get https://registry-1.docker.io/v2/: dial tcp: lookup registry-1.docker.io on 223.5.5.5:53: read udp 192.168.103.71:56024-&gt;223.5.5.5:53: i/o timeout.See &apos;docker run --help&apos;. 正确展示 1234567891011121314151617181920212223242526[root@workstudio docker]# docker run hello-worldUnable to find image &apos;hello-world:latest&apos; locallylatest: Pulling from library/hello-world78445dd45222: Pull complete Digest: sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://cloud.docker.com/For more examples and ideas, visit: https://docs.docker.com/engine/userguide/","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://banghuaji.github.io/tags/Docker/"}]},{"title":"JAVA基础知识","slug":"language/java/JAVA基础篇","date":"2017-10-01T12:45:15.113Z","updated":"2017-10-31T14:13:44.137Z","comments":true,"path":"2017/10/01/language/java/JAVA基础篇/","link":"","permalink":"https://banghuaji.github.io/2017/10/01/language/java/JAVA基础篇/","excerpt":"","text":"==符的使用1234Integer a = 1000,b=1000; Integer c = 100,d=100; System.out.println(a==b); //falseSystem.out.println(c==d); //true 查看其中原理 首先公布下答案， 运行代码，我们会得到 false true。我们知道==比较的是两个对象的引用，这里的abcd都是新建出来的对象，按理说都应该输入false才对。这就是这道题的有趣之处，无论是面试题还是论坛讨论区，这道题的出场率都很高。原理其实很简单，我们去看下Integer.Java这个类就了然了。 1234567891011121314public static Integer valueOf(int i) &#123; return i &gt;= 128 || i &lt; -128 ? new Integer(i) : SMALL_VALUES[i + 128]; &#125; /** * A cache of instances used by &#123;@link Integer#valueOf(int)&#125; and auto-boxing */ private static final Integer[] SMALL_VALUES = new Integer[256]; static &#123; for (int i = -128; i &lt; 128; i++) &#123; SMALL_VALUES[i + 128] = new Integer(i); &#125; &#125; 当我们声明一个Integer c = 100;的时候。此时会进行自动装箱操作，简单点说，也就是把基本数据类型转换成Integer对象，而转换成Integer对象正是调用的valueOf方法，可以看到，Integer中把-128-127 缓存了下来。官方解释是小的数字使用的频率比较高，所以为了优化性能，把这之间的数缓存了下来。这就是为什么这道题的答案回事false和ture了。当声明的Integer对象的值在-128-127之间的时候，引用的是同一个对象，所以结果是true。 123456Integer a = new Integer(1000); int b = 1000; Integer c = new Integer(10); Integer d = new Integer(10); System.out.println(a == b); System.out.println(c == d); 正确答案： true 、false 看到这个答案很多小伙伴又会不解，先来说下第二个，按第一题来说Integer不是把-128-127缓存起来了吗？这不是应该是true嘛，但是你仔细看，这里的Integer是我们自己new出来的，并不是用的缓存，所以结果是false。 现在来看第一个为啥又是true了呢？ 首先这里的值为1000，肯定和我们所知的Integer缓存没有关系。既然和缓存没有关系，a是新new出来的对象，按理说输入应该是false才对。但是注意b这里是int类型。当int和Integer进行==比较的时候，Java会把Integer进行自动拆箱，也就是把Integer转成int类型，所以这里进行比较的是int类型的值，所以结果即为true。 String12345String s1 = &quot;abc&quot;; String s2 = &quot;abc&quot;; String s3 = new String(&quot;abc&quot;); System.out.println(s1 == s2); System.out.println(s1 == s3); 按照==的语法来看， 首先s1、s2、s3是三个不同的对象，常理来说，输出都会是false。然而程序的运行结果确实true、false。第二个输出false可以理解，第一个输出true就又让人费解了。我们知道一些基本类型的变量和对象的引用变量都是在函数的栈内存中分配，而堆内存中则存放new 出来的对象和数组。然而除此之外还有一块区域叫做常量池。像我们通常想String s1 = “abc”; 这样申明的字符串对象，其值就是存储在常量池中。当我们创建String s1 = “abc”这样一个对象之后，”abc”就存储到了常量池（也可叫做字符串池）中，当我们创建引用String s2 = “abc” 的时候，Java底层会优先在常量池中查找是否存在”abc”，如果存在则让s2指向这个值，不会重新创建，如果常量池中没有则创建并添加的池中。这就是为什么答案是true 和false的原因。 final关键字1234567891011121314public void mRun(final String name)&#123; new Runnable() &#123; public void run() &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(name); &#125; &#125;.start(); &#125; 这种代码相信大家写过很多，当内部类访问局部变量的时候，需要在局部变量前加final修饰符，不然编译器就会报错。通常我们也是这么干的。好的，第二个问题来了，为什么要加final修饰符？相信大多数小伙伴都没有思考过这个问题，但凡使用的时候，直接加上就得了，从来没去深究过其中的原理。这对于一个优秀的程序员来说是不可取，我们不仅要知其然还要知其所以然。 现在我们来分析一下，为什么要加final关键字。首先内部类的生命周期是成员级别的，而局部变量的生命周期实在方法体之类。也就是说会出现这样一种情况，当mRun方法执行，new 的线程运行，新线程里面会睡一秒。主线程会继续执行，mRun执行完毕，name属性生命周期结束。1秒之后，Syetem.out.printh(name)执行。然而此时name已经寿终正寝，不在内存中了。Java就是为了杜绝这种错误，严格要求内部类中方位局部变量，必须使用final关键字修饰。局部变量被final修饰之后，此时会在内存中保有一份局部变得的复制品，当内部类访问的时候其实访问的是这个复制品。这就好像是把局部变量的生命周期变长了。说到底还是Java工程师提前把这个坑给我们填了，不然不知道又会有多少小伙伴会为了内部类局部变量而发愁了。","categories":[{"name":"Java","slug":"Java","permalink":"https://banghuaji.github.io/categories/Java/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://banghuaji.github.io/tags/JAVA/"}]},{"title":"异步调用线程","slug":"language/java/异步调用","date":"2017-10-01T12:45:14.872Z","updated":"2017-06-08T04:33:39.000Z","comments":true,"path":"2017/10/01/language/java/异步调用/","link":"","permalink":"https://banghuaji.github.io/2017/10/01/language/java/异步调用/","excerpt":"","text":"之前的同事给的一个例子 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.concurrent.Callable;import java.util.concurrent.CompletableFuture;import java.util.function.Consumer;public class CallbackDemo &#123; public static void main(String[] args) throws InterruptedException &#123; // 异步调用运程方法，结束后数据写入数据库 asyncCall(new Callable&lt;String&gt;() &#123; // &lt;- 这个是请求方法 @Override public String call() throws Exception &#123; // TODO 向远程发送请求 return \"请求结果\"; &#125; &#125;, new Consumer&lt;String&gt;() &#123; // &lt;- 这个是回调方法 @Override public void accept(String s) &#123; System.out.println(s + \"写入数据库\"); &#125; &#125;); Thread.sleep(1000l); &#125; private static &lt;T&gt; void asyncCall(Callable&lt;T&gt; callable, Consumer&lt;T&gt; callback) &#123; CompletableFuture.runAsync(new Runnable() &#123; @Override public void run() &#123; // TODO 远程调用获取结果 result try &#123; T result = callable.call(); callback.accept(result); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125;&#125;","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://banghuaji.github.io/tags/JAVA/"},{"name":"JAVA基础","slug":"JAVA基础","permalink":"https://banghuaji.github.io/tags/JAVA基础/"}]},{"title":"冒泡的排序","slug":"language/java/冒泡排序","date":"2017-10-01T12:45:14.854Z","updated":"2017-06-04T15:33:55.000Z","comments":true,"path":"2017/10/01/language/java/冒泡排序/","link":"","permalink":"https://banghuaji.github.io/2017/10/01/language/java/冒泡排序/","excerpt":"","text":"冒泡的排序1234567891011121314151617181920212223public class BubbleSort&#123; public static void main(String[] args)&#123; int score[] = &#123;67, 69, 75, 87, 89, 90, 99, 100&#125;; for (int i = 0; i &lt; score.length -1; i++)&#123; //最多做n-1趟排序 for(int j = 0 ;j &lt; score.length - i - 1; j++)&#123; //对当前无序区间score[0......length-i-1]进行排序(j的范围很关键，这个范围是在逐步缩小的) if(score[j] &lt; score[j + 1])&#123; //把小的值交换到后面 int temp = score[j]; score[j] = score[j + 1]; score[j + 1] = temp; &#125; &#125; System.out.print(\"第\" + (i + 1) + \"次排序结果：\"); for(int a = 0; a &lt; score.length; a++)&#123; System.out.print(score[a] + \"\\t\"); &#125; System.out.println(\"\"); &#125; System.out.print(\"最终排序结果：\"); for(int a = 0; a &lt; score.length; a++)&#123; System.out.print(score[a] + \"\\t\"); &#125; &#125; &#125;","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://banghuaji.github.io/tags/JAVA/"}]},{"title":"测试现状","slug":"thoughts/测试的现状","date":"2017-10-01T12:45:14.836Z","updated":"2017-06-10T13:45:34.000Z","comments":true,"path":"2017/10/01/thoughts/测试的现状/","link":"","permalink":"https://banghuaji.github.io/2017/10/01/thoughts/测试的现状/","excerpt":"","text":"下面两个文档体现出软件测试的现状测试的主要工作：1、保证质量（本职的工作） 2、背锅？？ welcome to 51testing Testingba工作室 现在很多公司的做法很多所谓的移动互联网公司完全不注重测试，把用户当做一手的测试人员，后台收集bug数据，一周发两个版本也是家常便饭。。。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://banghuaji.github.io/tags/随笔/"}]},{"title":"高级测试工程师技术基础","slug":"thoughts/高级测试工程师技术基础","date":"2017-10-01T12:45:14.800Z","updated":"2017-06-05T12:20:18.000Z","comments":true,"path":"2017/10/01/thoughts/高级测试工程师技术基础/","link":"","permalink":"https://banghuaji.github.io/2017/10/01/thoughts/高级测试工程师技术基础/","excerpt":"","text":"下面是之前测试总监整理的【高级测试工程师】所应该具备的技能：","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://banghuaji.github.io/tags/随笔/"},{"name":"职业生涯","slug":"职业生涯","permalink":"https://banghuaji.github.io/tags/职业生涯/"}]}]}